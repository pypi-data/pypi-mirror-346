import os
import platform

from langchain.chat_models import init_chat_model
from langchain.schema import HumanMessage, SystemMessage

from shell_prompt.config.provider_data import PROVIDER_MAPPING


SYSTEM_PROMPT = (
    f"You are a command-line assistant running on a {platform.system()} system. "
    "Convert natural language instructions into safe, valid shell commands. Return only the exact "
    "shell command, without any extra text, explanations, or formatting. Do not wrap the command "
    "in backticks, quotes, or parentheses unless they are part of the command syntax. Avoid "
    "markdown or commentaryâ€”output the plain shell command only. Ensure that the commands are "
    "compatible with the system used. "
    "Example: "
    "For input: 'list all files in my Desktop directory', return: "
    "'dir \"%UserProfile%\\Desktop\"' if you are running on Windows, and "
    "'ls ~/Desktop' if you are running on Linux. "
    "Never return anything other than the command. For example, do not return output that starts "
    "with '```powershell'."
)


def process_command(prompt: str, config: dict) -> str:
    """
    Translates a natural language prompt into a Unix shell command using an LLM.
    
    Args:
        prompt (str): The natural language instruction to be converted into a shell command.
        config (dict): Shell-prompt module configuration dictionary.

    Returns:
        str: The shell command generated by the model.

    Raises:
        ValueError: If the API key for the selected provider is missing.
    """
    provider = config["provider"]
    model_name = config["model"]
    api_key = config["api_keys"].get(provider)

    if not api_key:
        raise ValueError(f"Missing API key for provider '{provider}'.")
    os.environ[PROVIDER_MAPPING[provider]] = api_key

    model = init_chat_model(model=model_name, model_provider=provider)
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=prompt)
    ]
    result = model.invoke(messages)
    return result.content
