{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "#sys.path.append(\"//\")\n",
    "sys.path.append(\"../../micromet\")\n",
    "import micromet\n",
    "#from micromet.volk import ffp_climatology as ffp\n",
    "import micromet.volk as ffp\n",
    "from micromet import AmerifluxDataProcessor"
   ],
   "id": "bbef2a6e0b45cf07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "\n",
    "def multiply_geotiffs(input_a, input_b, output_path):\n",
    "    \"\"\"\n",
    "    Multiply two GeoTIFFs (A * B) after aligning them to the same\n",
    "    extent, resolution, and projection. The output is saved as a new GeoTIFF.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Open the first raster (this will be our \"reference\" grid) ---\n",
    "    with rasterio.open(input_a) as src_a:\n",
    "        profile_a = src_a.profile.copy()\n",
    "        # Read the full data array for A\n",
    "        data_a = src_a.read(1, masked=True)  # returns a MaskedArray if there's nodata\n",
    "\n",
    "        # We'll store the relevant spatial info to guide reprojecting raster B\n",
    "        ref_crs = src_a.crs\n",
    "        ref_transform = src_a.transform\n",
    "        ref_width = src_a.width\n",
    "        ref_height = src_a.height\n",
    "\n",
    "        # --- Open the second raster ---\n",
    "        with rasterio.open(input_b) as src_b:\n",
    "            # 1) We need both rasters in the same CRS. If different, we'll reproject B.\n",
    "            # 2) We also want B to match A's resolution and extent exactly.\n",
    "\n",
    "            # Create an empty array to hold the reprojected data from B\n",
    "            data_b_aligned = np.zeros((ref_height, ref_width), dtype=src_a.dtypes[0])\n",
    "\n",
    "            # Reproject (and resample) B to match A's grid\n",
    "            reproject(\n",
    "                source=rasterio.band(src_b, 1),\n",
    "                destination=data_b_aligned,\n",
    "                src_transform=src_b.transform,\n",
    "                src_crs=src_b.crs,\n",
    "                dst_transform=ref_transform,\n",
    "                dst_crs=ref_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "\n",
    "    # --- Perform the multiplication (masked arrays handle NoData gracefully) ---\n",
    "    # Convert data_b_aligned to a masked array if you want to respect NoData from A\n",
    "    data_b_masked = np.ma.array(data_b_aligned, mask=data_a.mask)\n",
    "    data_mult = data_a * data_b_masked\n",
    "\n",
    "    # --- Update the profile for the output ---\n",
    "    # We'll keep the same data type as A. If needed, you can change this (e.g., float32).\n",
    "    profile_out = profile_a.copy()\n",
    "    profile_out.update(dtype=str(data_mult.dtype), count=1, nodata=None)\n",
    "\n",
    "    # --- Write the result ---\n",
    "    with rasterio.open(output_path, 'w', **profile_out) as dst:\n",
    "        dst.write(data_mult.filled(0).astype(profile_out['dtype']), 1)  # fill masked with NaN or a NoData value\n",
    "\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    with rasterio.open(output_path) as src:\n",
    "        # Read the first band into a NumPy array\n",
    "        band_data = src.read(1)\n",
    "\n",
    "        # If you have \"NoData\" values and you'd like to exclude them, you can\n",
    "        # read the band as a masked array:\n",
    "        band_data = src.read(1, masked=True)\n",
    "        print(band_data)\n",
    "        # Then compute the sum of all values\n",
    "        total_sum = np.sum(band_data)\n",
    "\n",
    "        print(\"Sum of raster values:\", total_sum)\n",
    "    return total_sum\n",
    "\n",
    "\n",
    "\n",
    "output_raster = 'output_masked_resampled_3.tif'\n",
    "input_raster_B  = \"G:/My Drive/OpenET Exports/ensemble_et_2023_06_15_40011.tif\"\n",
    "input_raster_A   = \"./output/usutw/2023-06-15_weighted.tif\"\n",
    "tsum = multiply_geotiffs(input_raster_A, input_raster_B, output_raster)\n",
    "print(tsum)\n",
    "\n",
    "\n"
   ],
   "id": "d4e28bd1306f3855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "def multiply_directories_rast(dir1=None, dir2=None, out_dir=None):\n",
    "    \"\"\"\n",
    "    Multiply matching GeoTIFF rasters from two directories based on date patterns in their filenames.\n",
    "\n",
    "    The function looks for GeoTIFF files in `dir1` (filenames containing a date pattern\n",
    "    and ending with \"_weighted.tif\") and in `dir2` (filenames starting with \"ensemble_et_\").\n",
    "    It extracts the date (in the \"YYYY_MM_DD\" format) from the filenames of both directories.\n",
    "    For every matching date, the corresponding rasters are multiplied using the helper function\n",
    "    `multiply_geotiffs`. The results are saved as new rasters in the `out_dir` directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir1 : pathlib.Path or str\n",
    "        The directory containing the first set of GeoTIFF files (typically ending with \"_weighted.tif\").\n",
    "    dir2 : pathlib.Path or str\n",
    "        The directory containing the second set of GeoTIFF files (filenames typically start with \"ensemble_et_\").\n",
    "    out_dir : pathlib.Path or str\n",
    "        The directory where the resulting multiplied GeoTIFF files are saved. If it does not exist,\n",
    "        it is created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary keyed by date (pandas.Timestamp) where each value is the result of\n",
    "        the `multiply_geotiffs` function for that date's rasters.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function expects that the filename patterns in `dir1` and `dir2` include a date substring\n",
    "      in the format \"YYYY_MM_DD\".\n",
    "    - Any files not matching this pattern or without corresponding pairs in the other directory\n",
    "      are ignored.\n",
    "    - If any part of the file path does not exist, the function creates it.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> from pathlib import Path\n",
    "    >>> result = multiply_directories_rast(\n",
    "    ...     dir1=Path(\"./output/usutw/\"),\n",
    "    ...     dir2=Path(\"G:/My Drive/OpenET Exports/\"),\n",
    "    ...     out_dir=Path(\"./output/usutw_mult/\")\n",
    "    ... )\n",
    "    >>> print(result)  # Dictionary with dates and results of multiplication\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Set the paths to your two directories\n",
    "    if dir1 is None:\n",
    "        dir1 = pathlib.Path(\"./output/usutw/\")    # e.g., contains '...20210305.tif', etc.\n",
    "    if dir2 is None:\n",
    "        dir2 = pathlib.Path(\"G:/My Drive/OpenET Exports/\")\n",
    "    if out_dir is None:\n",
    "        out_dir = pathlib.Path(\"./output/usutw_mult/\")\n",
    "\n",
    "    # Check if it exists\n",
    "    if not out_dir.exists():\n",
    "        # Create the directory (including any necessary parent directories)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Directory {out_dir} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {out_dir} already exists.\")\n",
    "\n",
    "\n",
    "    # Regex pattern for an 8-digit date (adjust if your date format is different)\n",
    "    date_pattern = re.compile(r\"\\d{4}_\\d{2}_\\d{2}\")\n",
    "\n",
    "    # 1) Build a dictionary of {date_string: full_path} for files in dir2\n",
    "    date_to_file_dir2 = {}\n",
    "    for filename in dir2.glob(\"ensemble_et_*.tif\"):\n",
    "        match = date_pattern.search(filename.stem)\n",
    "        if match:\n",
    "            date_str = match.group(0)\n",
    "            date_to_file_dir2[date_str] = filename\n",
    "\n",
    "    tsum = {}\n",
    "\n",
    "    # 2) Iterate over the files in dir1, extract date, and check if we have a match in dir2\n",
    "    for filename in dir1.glob(\"*_weighted.tif\"):\n",
    "        dt_str = filename.stem.split(\"_\")[0].replace(\"-\",\"_\")\n",
    "        match = date_pattern.search(dt_str)\n",
    "        if match:\n",
    "            date_str = match.group(0)\n",
    "            # Check if this date exists in dir2\n",
    "            if date_str in date_to_file_dir2:\n",
    "                date = pd.to_datetime(date_str, format=\"%Y_%m_%d\")\n",
    "                file1 = filename\n",
    "                file2 = date_to_file_dir2[date_str]\n",
    "                output_raster = out_dir / f'weighted_ens_openet_{date_str}.tif'\n",
    "                tsum[date] = multiply_geotiffs(file1, file2, output_raster)\n",
    "    return tsum\n",
    "\n"
   ],
   "id": "4f04a42144c3ba8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "series= pd.Series(tsum)\n",
    "\n",
    "\n",
    "station = \"US-UTW\"\n",
    "metadata = micromet.load_configs(station,\n",
    "                 config_path='../../station_config/',\n",
    "                 secrets_path=\"../../secrets/config.ini\")\n",
    "df = micromet.fetch_and_preprocess_data(metadata[\"url\"], station, startdate='2023-01-01')\n",
    "s = df['et']\n",
    "s = s.where(s >= 0, 0)\n",
    "daily_stat_et = s.dropna().resample('D').sum(min_count=20)\n"
   ],
   "id": "919d4fe8b6b478ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "combined = pd.concat([daily_stat_et, series],axis=1).dropna()\n",
    "combined.columns = ['station_mm','eemetric_mm']#.plot()\n",
    "combined"
   ],
   "id": "ce97ad18036b09f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(combined['station_mm'], combined['eemetric_mm'])\n",
    "plt.grid()\n",
    "xy = np.arange(0,9,1)\n",
    "plt.plot(xy,xy,color='red',linestyle='--')\n",
    "plt.xlabel('Raw Station ET (mm)')\n",
    "plt.ylabel('eeMetric ET (mm)')\n",
    "plt.title(f\"Wellington {combined.first_valid_index():%Y-%m-%d} to {combined.last_valid_index():%Y-%m-%d}\")"
   ],
   "id": "aec9a9a87475d203"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pd.concat()",
   "id": "241011ef25531227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "station = \"US-UTW\"\n",
    "metadata = micromet.load_configs(station,\n",
    "                 config_path='../../station_config/',\n",
    "                 secrets_path=\"../../secrets/config.ini\")\n",
    "df = micromet.fetch_and_preprocess_data(metadata[\"url\"], station, startdate='2022-01-01')\n",
    "#df.groupby(pd.Grouper(freq='1D')).sum().loc['2023-06-15']"
   ],
   "id": "f072bd99797b4b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.groupby(pd.Grouper(freq='1D')).sum()",
   "id": "a1de720dd4ed5487"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
