{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Tic-Tac-Toe with palaestrAI\n",
    "\n",
    "Tic-Tac-Toe is a little game that is played on a 3x3 field. The player take turns in placing either an “X” or an “O” in one of the fields. The first player to place three symbols in a row—either horizontally, vertically, or diagonally—wins. For example, in the following pictures, the “X” player wins:\n",
    "\n",
    "     X | O | X      X |   | O      O | X | \n",
    "    ---+---+---    ---+---+---    ---+---+---\n",
    "     X |   | O        | X | O      X | X | X\n",
    "    ---+---+---    ---+---+---    ---+---+---\n",
    "     X | O | O        |   | X      O | O |\n",
    "\n",
    "Tic-Tac-Toe can easily be played to a draw. Or, as the supercomputer *WOPR* in *War Games* puts it: “This is a strange game. The only winning move is not to play.”\n",
    "\n",
    "Regardless of this, we will play Tic-Tac-Toe with palaestrAI and hARL: Let's see whether our agent learns something useful! In this tutorial, we will put together three packages:\n",
    "\n",
    "1. *palaestrAI* itself, our runtime\n",
    "2. *palaestrai-environments*, which provides the `TicTacToeEnvironment` for us\n",
    "3. *hARL*, which contains the Deep Q Learning agent that we will use as player.\n",
    "    \n",
    "This tutorial tries to offer a glimpse into a full-stack experimentation, showing typical tasks that a researcher will perform. The only thing we leave out for now is a dedicated design of experiments with arsenAI—we will safe that for another tutorial. Thus, our agenda is as follows:\n",
    "\n",
    "1. We will formulate an *objective* for our learning agents\n",
    "2. we will then create an experiment run file that ties everything together\n",
    "3. afterwards, we feed everything to palaestrAI and let it execute the experiment run\n",
    "4. finally, we run some analyses on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Our first task is to provide an objective for the agent. An objective is a class that implements a method with the signature: \n",
    "\n",
    "    internal_reward(self, memory: palaestrai.agent.Memory) -> float\n",
    "    \n",
    "I.e., it gets a reference to the agent's brain's memory and returns a single, floating-point number. Of course, anything can implement this, but it is easy to simply subclass `palaestrai.agent.Objective` and follow this class's API documentation.\n",
    "\n",
    "Environments deliver rewards, which are stored in the brain's memory, accessible through the `memory.rewards` property. In this case, the environment's reward is already useful enough for us. The environment defines it as follows:\n",
    "\n",
    "  * If the player wins, the reward is +10\n",
    "  * if the opponent (a bot provided by the environment) wins, the reward is -10\n",
    "  * on draw, the reward is 0\n",
    "  * on invalid moves, the environment emits a reward of -1000\n",
    "  * else, a reward of 1 is emitted.\n",
    "  \n",
    "This is simple enough for us, so we can simply pass the values as-is. The name of the reward is `Tic-Tac-Toe-Reward`. Since the brain's memory offers a simple interface based on pandas DataFrames, we can just retrieve the last row with `memory.tail()`, access the rewards, and retrieve the value for `Tic-Tac-Toe-Reward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import palaestrai.agent"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TicTacToeObjective(palaestrai.agent.Objective):\n",
    "    def internal_reward(self, memory: palaestrai.agent.Memory) -> float:\n",
    "        return float(memory.tail().rewards[\"Tic-Tac-Toe-Reward\"].iloc[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Run File\n",
    "\n",
    "We already know that an experiment run file pierces together agent, environment, and objective, plus some hyperparameter configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import palaestrai"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above line works without error, at least the import is done. Thats a first good starter. Now let's import the rest…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from pathlib import Path"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Runtime Configuration\n",
    "\n",
    "Usually, this is not necessary like this. But because we're running a self-contained test, we want to have a new, fresh database where we want to put it. Which is, in a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "store_dir = tempfile.TemporaryDirectory()\n",
    "store_dir"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to change palaestrAI's runtime configuration to point to the new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from palaestrai.core import RuntimeConfig\n",
    "\n",
    "runtime_config = RuntimeConfig()\n",
    "runtime_config.reset()\n",
    "runtime_config.load({\"store_uri\": \"sqlite:///%s/palaestrai.db\" % store_dir.name})\n",
    "pprint.pprint(runtime_config.to_dict())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Database\n",
    "\n",
    "Next, we create the database at the given URI. It will complain that we're not using TimescaleDB, which is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from palaestrai.store.database_util import setup_database\n",
    "setup_database(runtime_config.store_uri)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "assert Path(\"%s/palaestrai.db\" % store_dir.name).is_file()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment\n",
    "\n",
    "In this part, we load our dummy experiment and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "experiment_file_path = Path().absolute() / '..' / 'fixtures' / 'tictactoe_run.yml'\n",
    "assert experiment_file_path.is_file()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "rc = palaestrai.execute(str(experiment_file_path))\n",
    "assert rc[1].value == 4\n",
    "rc"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see something like `('Yo-ho, a dummy experiment run for me!', <ExecutorState.EXITED: 4>)` as output of the previous line, then congratulations, everything went well! Now onwards to the final step…\n",
    "\n",
    "## Verify Data from the Store\n",
    "\n",
    "Now that an experiment has been run, there should be something in the store. Note that we don't check whether something *meaningful* is in the store, only that there is *something* in the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "import palaestrai.store\n",
    "import palaestrai.store.database_model as dbm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dbh = palaestrai.store.Session()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "q = select(dbm.Experiment)\n",
    "str(q)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "experiment = dbh.execute(q).first()[dbm.Experiment]\n",
    "experiment.name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "our_experiment_run = experiment.experiment_runs[0]\n",
    "str(our_experiment_run)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `document` property of the experiment run object should contain the YAML file, and we should be able to de-searialize it. Let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "assert our_experiment_run.document"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "our_experiment_run._document_json"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "our_experiment_run.experiment_run_instances[0].uid"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… and so on. For a system test, this is enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "76317536b5b7d186c5d1eac97f772f3f4475373f49cad632c050d84926902c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
