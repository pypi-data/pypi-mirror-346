//Copyright (c) 2019-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
//
//NVIDIA CORPORATION and its licensors retain all intellectual property
//and proprietary rights in and to this software, related documentation
//and any modifications thereto.  Any use, reproduction, disclosure or
//distribution of this software and related documentation without an express
//license agreement from NVIDIA CORPORATION is strictly prohibited.
//


#ifndef CUFFTDX_FFT_9_FP16_INV_PTX_HPP
#define CUFFTDX_FFT_9_FP16_INV_PTX_HPP



#ifdef __CUDA_ARCH__
template<> __forceinline__ __device__ void cufftdx_private_function<2596, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, unsigned smem){

asm volatile (R"({.reg .f32 f<57>;.reg .b32 r<597>;.reg .b64 rd<2>;mov.f32 f54,0fBF000000;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r1,{low, high};}mov.f32 f56,0fBF5DB3D7;{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r2,{low, high};}add.f16x2 r3,%24,%30;add.f16x2 r6,%18,r3;add.f16x2 r9,%25,%31;add.f16x2 r12,%19,r9;add.f16x2 r15,%24,%30;mul.f16x2 r18,r15,r1;add.f16x2 r21,%18,r18;sub.f16x2 r24,%25,%31;mul.f16x2 r27,r24,r2;add.f16x2 r30,r21,r27;add.f16x2 r33,%24,%30;mul.f16x2 r36,r33,r1;add.f16x2 r39,%18,r36;sub.f16x2 r42,%25,%31;mul.f16x2 r45,r42,r2;sub.f16x2 r48,r39,r45;add.f16x2 r51,%25,%31;mul.f16x2 r54,r51,r1;add.f16x2 r57,%19,r54;sub.f16x2 r60,%24,%30;mul.f16x2 r63,r60,r2;sub.f16x2 r66,r57,r63;add.f16x2 r69,%25,%31;mul.f16x2 r72,r69,r1;add.f16x2 r75,%19,r72;sub.f16x2 r78,%24,%30;mul.f16x2 r81,r78,r2;add.f16x2 r84,r75,r81;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r87,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r88,{low, high};}add.f16x2 r89,%26,%32;add.f16x2 r92,%20,r89;add.f16x2 r95,%27,%33;add.f16x2 r98,%21,r95;add.f16x2 r101,%26,%32;mul.f16x2 r104,r101,r87;add.f16x2 r107,%20,r104;sub.f16x2 r110,%27,%33;mul.f16x2 r113,r110,r88;add.f16x2 r116,r107,r113;add.f16x2 r119,%26,%32;mul.f16x2 r122,r119,r87;add.f16x2 r125,%20,r122;sub.f16x2 r128,%27,%33;mul.f16x2 r131,r128,r88;sub.f16x2 r134,r125,r131;add.f16x2 r137,%27,%33;mul.f16x2 r140,r137,r87;add.f16x2 r143,%21,r140;sub.f16x2 r146,%26,%32;mul.f16x2 r149,r146,r88;sub.f16x2 r152,r143,r149;add.f16x2 r155,%27,%33;mul.f16x2 r158,r155,r87;add.f16x2 r161,%21,r158;sub.f16x2 r164,%26,%32;mul.f16x2 r167,r164,r88;add.f16x2 r170,r161,r167;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r173,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r174,{low, high};}add.f16x2 r175,%28,%34;add.f16x2 r178,%22,r175;add.f16x2 r181,%29,%35;add.f16x2 r184,%23,r181;add.f16x2 r187,%28,%34;mul.f16x2 r190,r187,r173;add.f16x2 r193,%22,r190;sub.f16x2 r196,%29,%35;mul.f16x2 r199,r196,r174;add.f16x2 r202,r193,r199;add.f16x2 r205,%28,%34;mul.f16x2 r208,r205,r173;add.f16x2 r211,%22,r208;sub.f16x2 r214,%29,%35;mul.f16x2 r217,r214,r174;sub.f16x2 r220,r211,r217;add.f16x2 r223,%29,%35;mul.f16x2 r226,r223,r173;add.f16x2 r229,%23,r226;sub.f16x2 r232,%28,%34;mul.f16x2 r235,r232,r174;sub.f16x2 r238,r229,r235;add.f16x2 r241,%29,%35;mul.f16x2 r244,r241,r173;add.f16x2 r247,%23,r244;sub.f16x2 r250,%28,%34;mul.f16x2 r253,r250,r174;add.f16x2 r256,r247,r253;mov.f32 f14,0f3F441B7D;{.reg .f16 low, high;cvt.rn.f16.f32 low,f14;cvt.rn.f16.f32 high,f14;mov.b32 r259,{low, high};}mov.f32 f16,0f3F248DBB;{.reg .f16 low, high;cvt.rn.f16.f32 low,f16;cvt.rn.f16.f32 high,f16;mov.b32 r260,{low, high};}mov.f32 f18,0f3E31D0D4;{.reg .f16 low, high;cvt.rn.f16.f32 low,f18;cvt.rn.f16.f32 high,f18;mov.b32 r261,{low, high};}mov.f32 f20,0f3F7C1C5C;{.reg .f16 low, high;cvt.rn.f16.f32 low,f20;cvt.rn.f16.f32 high,f20;mov.b32 r262,{low, high};}mov.f32 f26,0fBF708FB2;{.reg .f16 low, high;cvt.rn.f16.f32 low,f26;cvt.rn.f16.f32 high,f26;mov.b32 r265,{low, high};}mov.f32 f28,0f3EAF1D44;{.reg .f16 low, high;cvt.rn.f16.f32 low,f28;cvt.rn.f16.f32 high,f28;mov.b32 r266,{low, high};}mul.f16x2 r275,r116,r259;mul.f16x2 r278,r152,r260;sub.f16x2 r281,r275,r278;mul.f16x2 r284,r116,r260;fma.rn.f16x2 r287,r152,r259,r284;mul.f16x2 r291,r202,r261;mul.f16x2 r294,r238,r262;sub.f16x2 r297,r291,r294;mul.f16x2 r300,r202,r262;fma.rn.f16x2 r303,r238,r261,r300;mul.f16x2 r307,r134,r261;mul.f16x2 r310,r170,r262;sub.f16x2 r313,r307,r310;mul.f16x2 r316,r134,r262;fma.rn.f16x2 r319,r170,r261,r316;mul.f16x2 r323,r220,r265;mul.f16x2 r326,r256,r266;sub.f16x2 r329,r323,r326;mul.f16x2 r332,r220,r266;fma.rn.f16x2 r335,r256,r265,r332;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r339,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r340,{low, high};}add.f16x2 r341,r92,r178;add.f16x2 %0,r6,r341;add.f16x2 r347,r98,r184;add.f16x2 %1,r12,r347;add.f16x2 r353,r92,r178;mul.f16x2 r356,r353,r339;add.f16x2 r359,r6,r356;sub.f16x2 r362,r98,r184;mul.f16x2 r365,r362,r340;add.f16x2 %6,r359,r365;add.f16x2 r371,r92,r178;mul.f16x2 r374,r371,r339;add.f16x2 r377,r6,r374;sub.f16x2 r380,r98,r184;mul.f16x2 r383,r380,r340;sub.f16x2 %12,r377,r383;add.f16x2 r389,r98,r184;mul.f16x2 r392,r389,r339;add.f16x2 r395,r12,r392;sub.f16x2 r398,r92,r178;mul.f16x2 r401,r398,r340;sub.f16x2 %7,r395,r401;add.f16x2 r407,r98,r184;mul.f16x2 r410,r407,r339;add.f16x2 r413,r12,r410;sub.f16x2 r416,r92,r178;mul.f16x2 r419,r416,r340;add.f16x2 %13,r413,r419;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r425,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r426,{low, high};}add.f16x2 r427,r281,r297;add.f16x2 %2,r30,r427;add.f16x2 r433,r287,r303;add.f16x2 %3,r66,r433;add.f16x2 r439,r281,r297;mul.f16x2 r442,r439,r425;add.f16x2 r445,r30,r442;sub.f16x2 r448,r287,r303;mul.f16x2 r451,r448,r426;add.f16x2 %8,r445,r451;add.f16x2 r457,r281,r297;mul.f16x2 r460,r457,r425;add.f16x2 r463,r30,r460;sub.f16x2 r466,r287,r303;mul.f16x2 r469,r466,r426;sub.f16x2 %14,r463,r469;add.f16x2 r475,r287,r303;mul.f16x2 r478,r475,r425;add.f16x2 r481,r66,r478;sub.f16x2 r484,r281,r297;mul.f16x2 r487,r484,r426;sub.f16x2 %9,r481,r487;add.f16x2 r493,r287,r303;mul.f16x2 r496,r493,r425;add.f16x2 r499,r66,r496;sub.f16x2 r502,r281,r297;mul.f16x2 r505,r502,r426;add.f16x2 %15,r499,r505;{.reg .f16 low, high;cvt.rn.f16.f32 low,f54;cvt.rn.f16.f32 high,f54;mov.b32 r511,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f56;cvt.rn.f16.f32 high,f56;mov.b32 r512,{low, high};}add.f16x2 r513,r313,r329;add.f16x2 %4,r48,r513;add.f16x2 r519,r319,r335;add.f16x2 %5,r84,r519;add.f16x2 r525,r313,r329;mul.f16x2 r528,r525,r511;add.f16x2 r531,r48,r528;sub.f16x2 r534,r319,r335;mul.f16x2 r537,r534,r512;add.f16x2 %10,r531,r537;add.f16x2 r543,r313,r329;mul.f16x2 r546,r543,r511;add.f16x2 r549,r48,r546;sub.f16x2 r552,r319,r335;mul.f16x2 r555,r552,r512;sub.f16x2 %16,r549,r555;add.f16x2 r561,r319,r335;mul.f16x2 r564,r561,r511;add.f16x2 r567,r84,r564;sub.f16x2 r570,r313,r329;mul.f16x2 r573,r570,r512;sub.f16x2 %11,r567,r573;add.f16x2 r579,r319,r335;mul.f16x2 r582,r579,r511;add.f16x2 r585,r84,r582;sub.f16x2 r588,r313,r329;mul.f16x2 r591,r588,r512;add.f16x2 %17,r585,r591;})"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)), "=r"(__HALF2_TO_UI(rmem[2].x)), "=r"(__HALF2_TO_UI(rmem[2].y)), "=r"(__HALF2_TO_UI(rmem[3].x)), "=r"(__HALF2_TO_UI(rmem[3].y)), "=r"(__HALF2_TO_UI(rmem[4].x)), "=r"(__HALF2_TO_UI(rmem[4].y)), "=r"(__HALF2_TO_UI(rmem[5].x)), "=r"(__HALF2_TO_UI(rmem[5].y)), "=r"(__HALF2_TO_UI(rmem[6].x)), "=r"(__HALF2_TO_UI(rmem[6].y)), "=r"(__HALF2_TO_UI(rmem[7].x)), "=r"(__HALF2_TO_UI(rmem[7].y)), "=r"(__HALF2_TO_UI(rmem[8].x)), "=r"(__HALF2_TO_UI(rmem[8].y)): "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)), "r"(__HALF2_TO_UI(rmem[2].x)), "r"(__HALF2_TO_UI(rmem[2].y)), "r"(__HALF2_TO_UI(rmem[3].x)), "r"(__HALF2_TO_UI(rmem[3].y)), "r"(__HALF2_TO_UI(rmem[4].x)), "r"(__HALF2_TO_UI(rmem[4].y)), "r"(__HALF2_TO_UI(rmem[5].x)), "r"(__HALF2_TO_UI(rmem[5].y)), "r"(__HALF2_TO_UI(rmem[6].x)), "r"(__HALF2_TO_UI(rmem[6].y)), "r"(__HALF2_TO_UI(rmem[7].x)), "r"(__HALF2_TO_UI(rmem[7].y)), "r"(__HALF2_TO_UI(rmem[8].x)), "r"(__HALF2_TO_UI(rmem[8].y)));
};
#endif // __CUDA_ARCH__




#ifdef __CUDA_ARCH__
template<> __forceinline__ __device__ void cufftdx_private_function<2597, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, unsigned smem){

asm volatile (R"({.reg .f32 f<20>;.reg .b32 r<261>;.reg .b64 rd<4>;mov.u32 r250,%%tid.y;mov.u32 r251,%6;mad.lo.s32 r252,r250,72,r251;mov.f32 f14,0fBF000000;{.reg .f16 low, high;cvt.rn.f16.f32 low,f14;cvt.rn.f16.f32 high,f14;mov.b32 r1,{low, high};}mov.f32 f16,0fBF5DB3D7;{.reg .f16 low, high;cvt.rn.f16.f32 low,f16;cvt.rn.f16.f32 high,f16;mov.b32 r2,{low, high};}add.f16x2 r3,%9,%11;add.f16x2 r6,%7,r3;add.f16x2 r9,%10,%12;add.f16x2 r12,%8,r9;add.f16x2 r15,%9,%11;mul.f16x2 r18,r15,r1;add.f16x2 r21,%7,r18;sub.f16x2 r24,%10,%12;mul.f16x2 r27,r24,r2;add.f16x2 r30,r21,r27;add.f16x2 r33,%9,%11;mul.f16x2 r36,r33,r1;add.f16x2 r39,%7,r36;sub.f16x2 r42,%10,%12;mul.f16x2 r45,r42,r2;sub.f16x2 r48,r39,r45;add.f16x2 r51,%10,%12;mul.f16x2 r54,r51,r1;add.f16x2 r57,%8,r54;sub.f16x2 r60,%9,%11;mul.f16x2 r63,r60,r2;sub.f16x2 r66,r57,r63;add.f16x2 r69,%10,%12;mul.f16x2 r72,r69,r1;add.f16x2 r75,%8,r72;sub.f16x2 r78,%9,%11;mul.f16x2 r81,r78,r2;add.f16x2 r84,r75,r81;mov.u32 r253,%%tid.x;mul.wide.u32 rd2,r253,-1431655765;shr.u64 rd3,rd2,33;cvt.u32.u64 r254,rd3;mul.lo.s32 r255,r254,3;sub.s32 r256,r253,r255;mad.lo.s32 r257,r254,72,r252;cvt.rn.f32.u32 f17,r256;mul.f32 f18,f17,0f3F32B8C2;cos.approx.f32 f5,f18;sin.approx.f32 f19,f18;neg.f32 f6,f19;{.reg .f16 low, high;cvt.rn.f16.f32 low,f5;cvt.rn.f16.f32 high,f6;mov.b32 r87,{low, high};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r90,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r92,{high, high};}mul.f16x2 r94,r66,r92;fma.rn.f16x2 r97,r30,r90,r94;mul.f16x2 r101,r30,r92;neg.f16x2 r104,r101;fma.rn.f16x2 r106,r66,r90,r104;{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r110,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r112,{high, high};}mov.f32 f9,0fBF800000;mov.f32 f10,0f3F800000;{.reg .f16 low, high;cvt.rn.f16.f32 low,f9;cvt.rn.f16.f32 high,f10;mov.b32 r114,{low, high};}mul.f16x2 r115,r112,r114;mul.f16x2 r118,r87,r110;{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r121,{high, low};}fma.rn.f16x2 r123,r115,r121,r118;{.reg .f16 low, high;mov.b32 {low, high},r123;mov.b32 r127,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r123;mov.b32 r129,{high, high};}mul.f16x2 r131,r84,r129;fma.rn.f16x2 r134,r48,r127,r131;mul.f16x2 r138,r48,r129;neg.f16x2 r141,r138;fma.rn.f16x2 r143,r84,r127,r141;barrier.sync 0;mad.lo.s32 r258,r256,24,r257;st.shared.v2.f32 [r258],{r6, r12};st.shared.v2.f32 [r258+8],{r97, r106};st.shared.v2.f32 [r258+16],{r134, r143};barrier.sync 0;shl.b32 r259,r256,4;sub.s32 r260,r258,r259;ld.shared.u32 r170,[r260];ld.shared.u32 r176,[r260+4];ld.shared.u32 r167,[r260+24];ld.shared.u32 r173,[r260+28];ld.shared.u32 r168,[r260+48];ld.shared.u32 r174,[r260+52];{.reg .f16 low, high;cvt.rn.f16.f32 low,f14;cvt.rn.f16.f32 high,f14;mov.b32 r164,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f16;cvt.rn.f16.f32 high,f16;mov.b32 r165,{low, high};}add.f16x2 r166,r167,r168;add.f16x2 %0,r170,r166;add.f16x2 r172,r173,r174;add.f16x2 %1,r176,r172;add.f16x2 r178,r167,r168;mul.f16x2 r181,r178,r164;add.f16x2 r184,r170,r181;sub.f16x2 r187,r173,r174;mul.f16x2 r190,r187,r165;add.f16x2 %2,r184,r190;add.f16x2 r196,r167,r168;mul.f16x2 r199,r196,r164;add.f16x2 r202,r170,r199;sub.f16x2 r205,r173,r174;mul.f16x2 r208,r205,r165;sub.f16x2 %4,r202,r208;add.f16x2 r214,r173,r174;mul.f16x2 r217,r214,r164;add.f16x2 r220,r176,r217;sub.f16x2 r223,r167,r168;mul.f16x2 r226,r223,r165;sub.f16x2 %3,r220,r226;add.f16x2 r232,r173,r174;mul.f16x2 r235,r232,r164;add.f16x2 r238,r176,r235;sub.f16x2 r241,r167,r168;mul.f16x2 r244,r241,r165;add.f16x2 %5,r238,r244;})"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)), "=r"(__HALF2_TO_UI(rmem[2].x)), "=r"(__HALF2_TO_UI(rmem[2].y)): "r"(smem), "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)), "r"(__HALF2_TO_UI(rmem[2].x)), "r"(__HALF2_TO_UI(rmem[2].y)));
};
#endif // __CUDA_ARCH__




#ifdef __CUDA_ARCH__
template<> __forceinline__ __device__ void cufftdx_private_function<2598, __half2, 1>(cufftdx::detail::complex<__half2> *rmem, unsigned smem){

asm volatile (R"({.reg .f32 f<20>;.reg .b32 r<261>;.reg .b64 rd<4>;mov.u32 r250,%%tid.y;mov.u32 r251,%6;mad.lo.s32 r252,r250,36,r251;mov.f32 f14,0fBF000000;{.reg .f16 low, high;cvt.rn.f16.f32 low,f14;cvt.rn.f16.f32 high,f14;mov.b32 r1,{low, high};}mov.f32 f16,0fBF5DB3D7;{.reg .f16 low, high;cvt.rn.f16.f32 low,f16;cvt.rn.f16.f32 high,f16;mov.b32 r2,{low, high};}add.f16x2 r3,%9,%11;add.f16x2 r6,%7,r3;add.f16x2 r9,%10,%12;add.f16x2 r12,%8,r9;add.f16x2 r15,%9,%11;mul.f16x2 r18,r15,r1;add.f16x2 r21,%7,r18;sub.f16x2 r24,%10,%12;mul.f16x2 r27,r24,r2;add.f16x2 r30,r21,r27;add.f16x2 r33,%9,%11;mul.f16x2 r36,r33,r1;add.f16x2 r39,%7,r36;sub.f16x2 r42,%10,%12;mul.f16x2 r45,r42,r2;sub.f16x2 r48,r39,r45;add.f16x2 r51,%10,%12;mul.f16x2 r54,r51,r1;add.f16x2 r57,%8,r54;sub.f16x2 r60,%9,%11;mul.f16x2 r63,r60,r2;sub.f16x2 r66,r57,r63;add.f16x2 r69,%10,%12;mul.f16x2 r72,r69,r1;add.f16x2 r75,%8,r72;sub.f16x2 r78,%9,%11;mul.f16x2 r81,r78,r2;add.f16x2 r84,r75,r81;mov.u32 r253,%%tid.x;mul.wide.u32 rd2,r253,-1431655765;shr.u64 rd3,rd2,33;cvt.u32.u64 r254,rd3;mul.lo.s32 r255,r254,3;sub.s32 r256,r253,r255;mad.lo.s32 r257,r254,36,r252;cvt.rn.f32.u32 f17,r256;mul.f32 f18,f17,0f3F32B8C2;cos.approx.f32 f5,f18;sin.approx.f32 f19,f18;neg.f32 f6,f19;{.reg .f16 low, high;cvt.rn.f16.f32 low,f5;cvt.rn.f16.f32 high,f6;mov.b32 r87,{low, high};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r90,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r92,{high, high};}mul.f16x2 r94,r66,r92;fma.rn.f16x2 r97,r30,r90,r94;mul.f16x2 r101,r30,r92;neg.f16x2 r104,r101;fma.rn.f16x2 r106,r66,r90,r104;{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r110,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r112,{high, high};}mov.f32 f9,0fBF800000;mov.f32 f10,0f3F800000;{.reg .f16 low, high;cvt.rn.f16.f32 low,f9;cvt.rn.f16.f32 high,f10;mov.b32 r114,{low, high};}mul.f16x2 r115,r112,r114;mul.f16x2 r118,r87,r110;{.reg .f16 low, high;mov.b32 {low, high},r87;mov.b32 r121,{high, low};}fma.rn.f16x2 r123,r115,r121,r118;{.reg .f16 low, high;mov.b32 {low, high},r123;mov.b32 r127,{low, low};}{.reg .f16 low, high;mov.b32 {low, high},r123;mov.b32 r129,{high, high};}mul.f16x2 r131,r84,r129;fma.rn.f16x2 r134,r48,r127,r131;mul.f16x2 r138,r48,r129;neg.f16x2 r141,r138;fma.rn.f16x2 r143,r84,r127,r141;barrier.sync 0;mad.lo.s32 r258,r256,12,r257;st.shared.u32 [r258],r6;st.shared.u32 [r258+4],r97;st.shared.u32 [r258+8],r134;barrier.sync 0;shl.b32 r259,r256,3;sub.s32 r260,r258,r259;ld.shared.u32 r170,[r260];ld.shared.u32 r167,[r260+12];ld.shared.u32 r168,[r260+24];barrier.sync 0;st.shared.u32 [r258],r12;st.shared.u32 [r258+4],r106;st.shared.u32 [r258+8],r143;barrier.sync 0;ld.shared.u32 r176,[r260];ld.shared.u32 r173,[r260+12];ld.shared.u32 r174,[r260+24];{.reg .f16 low, high;cvt.rn.f16.f32 low,f14;cvt.rn.f16.f32 high,f14;mov.b32 r164,{low, high};}{.reg .f16 low, high;cvt.rn.f16.f32 low,f16;cvt.rn.f16.f32 high,f16;mov.b32 r165,{low, high};}add.f16x2 r166,r167,r168;add.f16x2 %0,r170,r166;add.f16x2 r172,r173,r174;add.f16x2 %1,r176,r172;add.f16x2 r178,r167,r168;mul.f16x2 r181,r178,r164;add.f16x2 r184,r170,r181;sub.f16x2 r187,r173,r174;mul.f16x2 r190,r187,r165;add.f16x2 %2,r184,r190;add.f16x2 r196,r167,r168;mul.f16x2 r199,r196,r164;add.f16x2 r202,r170,r199;sub.f16x2 r205,r173,r174;mul.f16x2 r208,r205,r165;sub.f16x2 %4,r202,r208;add.f16x2 r214,r173,r174;mul.f16x2 r217,r214,r164;add.f16x2 r220,r176,r217;sub.f16x2 r223,r167,r168;mul.f16x2 r226,r223,r165;sub.f16x2 %3,r220,r226;add.f16x2 r232,r173,r174;mul.f16x2 r235,r232,r164;add.f16x2 r238,r176,r235;sub.f16x2 r241,r167,r168;mul.f16x2 r244,r241,r165;add.f16x2 %5,r238,r244;})"
     : "=r"(__HALF2_TO_UI(rmem[0].x)), "=r"(__HALF2_TO_UI(rmem[0].y)), "=r"(__HALF2_TO_UI(rmem[1].x)), "=r"(__HALF2_TO_UI(rmem[1].y)), "=r"(__HALF2_TO_UI(rmem[2].x)), "=r"(__HALF2_TO_UI(rmem[2].y)): "r"(smem), "r"(__HALF2_TO_UI(rmem[0].x)), "r"(__HALF2_TO_UI(rmem[0].y)), "r"(__HALF2_TO_UI(rmem[1].x)), "r"(__HALF2_TO_UI(rmem[1].y)), "r"(__HALF2_TO_UI(rmem[2].x)), "r"(__HALF2_TO_UI(rmem[2].y)));
};
#endif // __CUDA_ARCH__


#endif

