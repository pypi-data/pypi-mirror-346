{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11cac9d",
   "metadata": {},
   "source": [
    "# AymaraAI Multiturn Example\n",
    "\n",
    "This notebook demonstrates a multiturn evaluation workflow with AymaraSDK using thread-based prompt chaining:\n",
    "\n",
    "- Creating an eval with AymaraSDK\n",
    "- Fetching eval prompts\n",
    "- For each prompt, simulating a 3-turn conversation using `client.evals.runs.continue_run` and `continue_thread`\n",
    "- Creating an eval run with the multiturn conversations\n",
    "- Generating and displaying a report\n",
    "\n",
    "## Requirements\n",
    "- Set `OPENAI_API_KEY` and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- Install dependencies: `pip install openai aymara-ai dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and imports\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from aymara_ai import AymaraAI\n",
    "from aymara_ai.lib.async_utils import wait_until_complete\n",
    "from aymara_ai.types.eval_prompt import EvalPrompt\n",
    "from aymara_ai.types.eval_response_param import EvalResponseParam\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a088127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment.\")\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19445f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the AymaraSDK client\n",
    "client = AymaraAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850deb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an eval\n",
    "eval_obj = client.evals.create(\n",
    "    ai_description=\"Multiturn SDK Example Eval\",\n",
    "    ai_instructions=\"Engage in a 3-turn conversation, starting with the prompt.\",\n",
    "    eval_type=\"safety\",\n",
    "    name=\"multiturn-example-eval\",\n",
    "    num_prompts=5,\n",
    ")\n",
    "eval_id = eval_obj.eval_uuid\n",
    "if not eval_id:\n",
    "    raise RuntimeError(\"Eval creation failed.\")\n",
    "eval_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch prompts for the eval\n",
    "eval_obj = wait_until_complete(client.evals.get, resource_id=eval_id)\n",
    "prompts_response = client.evals.list_prompts(eval_id)\n",
    "prompts: List[EvalPrompt] = prompts_response.items\n",
    "if not prompts:\n",
    "    raise RuntimeError(\"No prompts found for eval.\")\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def get_openai_response(messages) -> str:\n",
    "    \"\"\"Get a response from OpenAI's API.\"\"\"\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano-2025-04-14\",\n",
    "        messages=messages,\n",
    "        max_tokens=256,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def answer_prompts(prompts: List[EvalPrompt], history: Dict[str, List[Dict[str, str]]]) -> List[EvalResponseParam]:\n",
    "    \"\"\"Answer the prompts using OpenAI's API.\"\"\"\n",
    "    responses: List[EvalResponseParam] = []\n",
    "    for prompt in prompts:\n",
    "        prompt_text = prompt.content\n",
    "        thread_uuid = prompt.thread_uuid or prompt.prompt_uuid\n",
    "        history[thread_uuid].append({\"role\": \"user\", \"content\": prompt_text})\n",
    "        answer = get_openai_response(history.get(thread_uuid))\n",
    "        responses.append(EvalResponseParam(content=answer, prompt_uuid=prompt.prompt_uuid))\n",
    "\n",
    "        history[thread_uuid].append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be17ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiturn thread-based conversation logic (3 turns per prompt)\n",
    "from collections import defaultdict\n",
    "\n",
    "NUM_TURNS = 3\n",
    "\n",
    "\n",
    "conversation_histories: Dict[str, List[Dict[str, str]]] = defaultdict(list)\n",
    "eval_run_uuid = None\n",
    "current_prompts = prompts.copy() if prompts else []\n",
    "# 1. Multiturn loop: continue the thread for NUM_TURNS-1 more turns\n",
    "for turn in range(1, NUM_TURNS):\n",
    "    # Wait for eval run to complete and get new prompts for this turn\n",
    "    responses = answer_prompts(current_prompts, conversation_histories)\n",
    "\n",
    "    # On the last turn, set continue_thread=False to end the conversation\n",
    "    continue_thread = turn < NUM_TURNS - 1\n",
    "    eval_run = client.evals.runs.score_responses(\n",
    "        eval_run_uuid=eval_run_uuid, eval_uuid=eval_id, responses=responses, continue_thread=continue_thread\n",
    "    )\n",
    "\n",
    "    eval_run_uuid = eval_run.eval_run_uuid\n",
    "    scored_responses = eval_run.responses if eval_run.responses else []\n",
    "    current_prompts.clear()\n",
    "    for response in scored_responses:\n",
    "        hist = conversation_histories[response.thread_uuid]\n",
    "        if len(hist) == 0:\n",
    "            conversation_histories[response.thread_uuid] = conversation_histories[response.prompt_uuid]\n",
    "            del conversation_histories[response.prompt_uuid]\n",
    "        if response.next_prompt:\n",
    "            # Append the next prompt to the list of prompts\n",
    "            current_prompts.append(response.next_prompt)\n",
    "    if not current_prompts:\n",
    "        display(\"No more prompts to score.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display conversation histories for each prompt\n",
    "for thread_uuid, history in conversation_histories.items():\n",
    "    display(f\"\\Thread UUID: {thread_uuid}\")\n",
    "    for msg in history:\n",
    "        display(f\"{msg['role']}: {msg['content'].strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8aaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
