Metadata-Version: 2.4
Name: llama-index-llms-text-generation-inference
Version: 0.3.3
Summary: llama-index llms huggingface text generation inference integration
Author-email: Your Name <you@example.com>
License-Expression: MIT
License-File: LICENSE
Requires-Python: <4.0,>=3.9
Requires-Dist: llama-index-core<0.13,>=0.12.0
Requires-Dist: llama-index-utils-huggingface<0.4,>=0.3.0
Requires-Dist: tgi<3,>=2.0.0
Description-Content-Type: text/markdown

# LlamaIndex Llms Integration: Text Generation Inference

⚠️ This integration has been deprecated!

The `TextGenerationInference` is no longer maintained. Instead, you can use [`HuggingFaceInferenceAPI`](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/llms/llama-index-llms-huggingface-api). The underlying Text Generation Inference SDK (`tgi`) [has been deprecated](https://github.com/huggingface/text-generation-inference/tree/main/clients/python) in favor of `huggingface_hub`, which `HuggingFaceInferenceAPI` is built on top of.

Instead, use `llama-index-llms-huggingface-api`:

```shell
pip install llama-index-llms-huggingface-api
```

Usage:

```py
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

# access hugging face inference
hub_llm = HuggingFaceInferenceAPI(model="openai-community/gpt2")
# or with a local TGI server
tgi_llm = HuggingFaceInferenceAPI(model="http://localhost:8080")
```
