Metadata-Version: 2.3
Name: onnxnpu
Version: 0.1.0
Summary: CLI toolkit to check, optimize and modify ONNX models for NPU deployment
License: MIT
Author: Mason Huang
Author-email: masonhuang0320@gmail.com
Requires-Python: >=3.9
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: onnx (>=1.17.0,<2.0.0)
Project-URL: Homepage, https://github.com/HuangMason320/onnxnpu-toolkit
Project-URL: Repository, https://github.com/HuangMason320/onnxnpu-toolkit
Description-Content-Type: text/markdown

# ONNXNPU Toolkit

[![PyPI version]][pypi-url] [![License]][license-url]

`onnxnpu` is a lightweight CLI toolkit that **inspects, optimizes, and modifies ONNX models *before* you convert or deploy them to NPUs**.

> "Catch unsupported operators early before they derail your model."
> â€” *Mason Huang*

## âœ¨Â FeaturesÂ (v0.1Â â€”Â released)

| Feature               | Description                                                                                                           |
| --------------------- | --------------------------------------------------------------------------------------------------------------------- |
| **Operator scan**     | Fast, dependencyâ€‘free static analysis ofÂ `.onnx`Â files                                                                 |
| **Hardware profiles** | Builtâ€‘in JSON compatibility tables for common NPUs (KL520â€¯/â€¯530â€¯/â€¯630â€¯/â€¯720â€¯/â€¯730Â â€¦) with an override mechanism        |
| **Clear report**      | CLI tableâ€¯ï¼‹â€¯optionalâ€¯JSONÂ /Â Markdown export; highlights unsupported ops and optionalâ€‘feature gaps                      |
| **Actionable hints**  | Suggestions and links to official docs for each unsupported operator                                                  |
| **Opset update**      | Upgrade model opset (12â€¯â€“â€¯18) to match target hardware                                                                |

---

<details>
<summary>ğŸ§­Â Roadmap</summary>

| Version | TargetÂ Date* | MajorÂ Items                                                                                           | Notes / Dependencies                                                    |
| ------- | ------------ | ------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------- |
| **0.2 â€“ ValidationÂ &Â Reporting** | MayÂ 2025 | â€¢ Shape checker enforcing 4â€‘DÂ `(1,â€¯C,â€¯H,â€¯W)` constraint<br>â€¢ Rich Markdownâ€¯/â€¯JSON report templates for CI badges | Uses ONNX shapeâ€‘inference to avoid manual parsing                       |
| **0.3 â€“ GraphÂ SimplificationÂ &Â Slimming** | JunÂ 2025 | â€¢ Integrate **onnxâ€‘sim** (`--simplify`)<br>â€¢ Model slimming (`--prune`, `--quantize`)<br>â€¢ Bundle Kneron **optimizer_scripts** (BNâ€‘Conv fuse, Dropout removalÂ â€¦) | Requires onnxâ€‘simâ€¯â‰¥â€¯0.4; quantization via ONNXÂ QOps                     |
| **0.4 â€“ AutomaticÂ OpÂ Replacement** | JulÂ 2025 | â€¢ `--replace` mapping table (e.g.,Â `ReshapeÂ â†’Â Flatten`)<br>â€¢ Fallback to custom kernels / plugin stubs           | Needs rule setÂ ï¼‹ regression tests                                       |
| **0.5 â€“ InteractiveÂ Viewer**      | AugÂ 2025 | â€¢ `onnxnpu view` dragâ€‘andâ€‘drop web UI<br>â€¢ Highlight unsupported nodes directly on the graph<br>â€¢ Downloadable HTML report | Likely ReactÂ + ONNXâ€‘JS; demo hosted on GitHubÂ Pages                     |
| **0.6 â€“ ExtensibilityÂ &Â Ecosystem** | SepÂ 2025 | â€¢ Plugin system via Python entryâ€‘points<br>â€¢ Community hardwareâ€‘profile submission flow<br>â€¢ Freeze stable APIÂ v1.0 | Plan to publish on condaâ€‘forge after API stabilisation                  |

\*Â Dates are tentative and may shift based on resources.
</details>

## ğŸš€ Quick start

You can use two different CLI commands: `onnxnpu` or `onpu` to check, optimize, and modify your ONNX models for NPU deployment. Both commands provide identical functionality with the same syntax.

| Command                                       | Description                                           |
|-----------------------------------------------|-------------------------------------------------------|
| `pip install onnxnpu`                         | Install latest package from PyPI                      |
| `onnxnpu check my_model.onnx -p KL720`           | Check `my_model.onnx` for the KL720 hardware profile  |
| `onnxnpu check my_model.onnx`                    | Check `my_model.onnx` for all built-in profiles       |
| `onnxnpu opt my_model.onnx --opset 13`           | Update model to opset 13                              |
| `onnxnpu -V`, `onnxnpu --version`                   | Show version number and exit                          |

### Sample output

```
Model summary â€“ my_model.onnx
IR version : 6    Opset : 11
Inputs  : input  float32  [1, 3, 112, 112]
Outputs : output  float32  [1, 512]
Dynamic axes : None detected âœ“

my_model.onnx Â· IR 6 Â· KL520
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Status  Operator   Count   Notes                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   âœ“      Conv        27                                      â”‚
â”‚   âœ“      Relu        27                                      â”‚
â”‚   âœ—      Elu          5     Not supported on KL520           â”‚
â”‚   âœ“      MaxPool      5                                      â”‚
â”‚   âœ—      Resize       2     Only linear/nearest modes OK     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
âš   2 unsupported operator(s) detected.
```

<!-- ## ğŸ› ï¸ Development & Publishing

é€é Poetry ä¸€éµå»ºç½®èˆ‡ç™¼ä½ˆï¼š

```bash
# 1. build wheel and sdist
poetry build

# 2. ï¼ˆTest versionï¼‰publish to TestPyPI
poetry config repositories.testpypi https://test.pypi.org/legacy/
poetry config pypi-token.testpypi <YOUR_TEST_PYPI_TOKEN>
poetry publish -r testpypi

# 3. Publish official version to PyPI
poetry config pypi-token.pypi <YOUR_PYPI_TOKEN>
poetry publish
``` -->

## ğŸ§‘â€ğŸ’» API usage

```python
from onnxnpu import Checker, load_profile

checker = Checker("my_model.onnx", profile=load_profile("kl720"))
report = checker.run()
print(report.to_markdown())

# Update opset version
from onnxnpu import update_opset_version
update_opset_version("my_model.onnx", target_version=13)
```

## ğŸ“– HardwareÂ profiles

Profiles live under `onnxnpu/profiles/*.json`.
Each profile declares the operators, attributes, and constraints supported by a particular accelerator.
See [`docs/PROFILE_SCHEMA.md`](docs/PROFILE_SCHEMA.md) for the JSON schema.

Contributions for new hardware are very welcome!

<!-- ## ğŸ¤ Contributing

We love pull requests! Please read `CONTRIBUTING.md` and open an issue before you start a large refactor so we can align on design.

Coding conventions follow **PEPÂ 8** with the Black formatter. -->

### A note on language

The primary language of this README is **English** for wider community reach.  A Traditional Chinese translation will be added soon.


[PyPI version]: https://img.shields.io/pypi/v/onnxnpu
[pypi-url]: https://pypi.org/project/onnxnpu
[Build status]: https://img.shields.io/github/actions/workflow/status/HuangMason320/onnx-checker/ci.yml?branch=main
[ci-url]: https://github.com/HuangMason320/onnxnpu-toolkit/actions
[License]: https://img.shields.io/github/license/HuangMason320/onnxnpu-toolkit
[license-url]: https://pypi.org/project/onnxnpu-toolkit/

