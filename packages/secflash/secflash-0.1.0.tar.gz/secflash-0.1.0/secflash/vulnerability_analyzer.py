"""
Vulnerability analyzer for scanning networks and generating reports.
"""

import sqlite3
import logging
import json
import os
import zipfile
import re
from typing import Dict, List, Tuple, Optional, Any
import nvdlib
import time
import requests

from .report_generator import ReportGenerator
from .config import config
from .nvd_client import NVDClient
from .database import NVDDatabase

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("vulnerability_analyzer.log"),
        logging.StreamHandler()
    ]
)


class VulnerabilityAnalyzer:
    """A class for analyzing security vulnerabilities.
    
    This class provides functionality to analyze security vulnerabilities
    using the National Vulnerability Database (NVD).
    
    Attributes:
        client (NVDClient): Client for interacting with NVD API
        db (NVDDatabase): Database for storing vulnerability data
    """

    def __init__(self, db_path: Optional[str] = None):
        """Initialize the VulnerabilityAnalyzer with NVD client and database."""
        self.db_path = db_path if db_path is not None else config.NVD_DB_PATH
        self.report_generator = ReportGenerator()
        self.api_key = config.NVD_API_KEY
        self._db_conn = None
        if not self.api_key:
            logging.info("No NVD API key provided. Operating without API key.")
        else:
            logging.info(f"Using API key: {self.api_key[:8]}...")

        # CPE mapping for known services
        self.CPE_MAPPING = {
            "apache httpd": {"vendor": "apache", "part": "a", "product": "http_server"},
            "nginx": {"vendor": "nginx", "part": "a", "product": "nginx"},
            "mysql": {"vendor": "oracle", "part": "a", "product": "mysql"},
            "windows server": {"vendor": "microsoft", "part": "o", "product": "windows_server"},
            "wordpress": {"vendor": "wordpress", "part": "a", "product": "wordpress"},
            "tomcat": {"vendor": "apache", "part": "a", "product": "tomcat"},
            "openssl": {"vendor": "openssl", "part": "a", "product": "openssl"},
            "php": {"vendor": "php", "part": "a", "product": "php"},
            "java": {"vendor": "oracle", "part": "a", "product": "jdk"},
            "openssh": {"vendor": "openbsd", "part": "a", "product": "openssh"},
            "smb": {"vendor": "samba", "part": "a", "product": "samba"},
            "ubuntu": {"vendor": "canonical", "part": "o", "product": "ubuntu_linux"}
        }

        self.client = NVDClient()
        self.db = NVDDatabase()

        self._initialize_database()

    def _initialize_database(self):
        """Initialize the SQLite database."""
        try:
            logging.info(f"Attempting to initialize database at {self.db_path}")
            self._db_conn = sqlite3.connect(self.db_path)
            cursor = self._db_conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS vulnerabilities (
                    cve_id TEXT,
                    cpe TEXT,
                    description TEXT,
                    published TEXT,
                    last_modified TEXT,
                    cvss_score REAL,
                    cvss_vector TEXT,
                    vuln_references TEXT,
                    configurations TEXT,
                    PRIMARY KEY (cve_id, cpe)
                )
            """)
            
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_cpe ON vulnerabilities(cpe)")
            
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='vulnerabilities'")
            if not cursor.fetchone():
                logging.error("Failed to create vulnerabilities table")
                raise sqlite3.OperationalError("Failed to create vulnerabilities table")
                
            self._db_conn.commit()
            logging.info(f"Database initialized successfully at {self.db_path}")
        except sqlite3.Error as e:
            logging.error(f"Failed to initialize database: {str(e)}")
            raise

    def _connect_db(self) -> sqlite3.Connection:
        """Connect to the SQLite database."""
        if self._db_conn is None:
            try:
                self._db_conn = sqlite3.connect(self.db_path)
                logging.info("Connected to database successfully")
            except sqlite3.Error as e:
                logging.error(f"Failed to connect to database: {str(e)}")
                raise
        return self._db_conn

    def _get_cpe_for_service(self, service: str) -> Tuple[str, str, str, Optional[str]]:
        """Extract vendor, product, and version from a service string."""
        service_lower = service.lower()
        version = None

        if "windows server" in service_lower:
            version_match = re.search(r'windows server\s+(\d{4}|\d+\.\d+\.\d+)', service_lower)
            if version_match:
                version = version_match.group(1)
            service_name = "windows server"
        else:
            version_match = re.search(r'(\d+\.\d+\.\d+[\w\-]*)', service_lower)
            if version_match:
                version = version_match.group(1)
                service_name = service_lower.replace(version, '').strip()
            else:
                service_name = service_lower

        for key, cpe_info in self.CPE_MAPPING.items():
            if key in service_name:
                return (
                    cpe_info["part"],
                    cpe_info["vendor"],
                    cpe_info["product"],
                    version
                )
        logging.warning(f"No CPE mapping found for service: {service}")
        return "a", "unknown", "unknown", None

    def _validate_cpe(self, part: str, vendor: str, product: str, version: Optional[str] = None) -> Optional[str]:
        """Validate and return a CPE string."""
        if vendor == "unknown" or product == "unknown":
            logging.warning(f"Invalid vendor or product: {vendor}:{product}")
            return None

        cpe_base = f"cpe:2.3:{part}:{vendor}:{product}:{version if version else '*'}:*:*:*:*:*:*:*"
        logging.info(f"Generated CPE: {cpe_base}")

        try:
            logging.info(f"Searching CPE for {vendor}:{product} (version: {version})")
            cpe_results = nvdlib.searchCPE(
                keywordSearch=f"{vendor} {product} {version}" if version else f"{vendor} {product}",
                key=self.api_key if self.api_key else None,
                delay=6 if not self.api_key else 0.6
            )
            for cpe in cpe_results:
                cpe_name = cpe.cpeName.lower()
                if vendor.lower() in cpe_name and product.lower().replace('_', '') in cpe_name.replace('_', '').replace('-', ''):
                    if product == "http_server" and "http_server" not in cpe_name:
                        continue
                    if version and version.lower() in cpe_name:
                        logging.info(f"Found matching CPE: {cpe.cpeName}")
                        return cpe.cpeName
                    elif not version:
                        logging.info(f"Found matching CPE: {cpe.cpeName}")
                        return cpe.cpeName
            logging.warning(f"No matching CPE found for {vendor}:{product} (version: {version})")
        except Exception as e:
            logging.error(f"CPE search error for {vendor}:{product}: {str(e)}")

        logging.info(f"Using generated CPE as fallback: {cpe_base}")
        return cpe_base

    def _query_cached_vulnerabilities(self, part: str, vendor: str, product: str, version: Optional[str] = None) -> List[Dict]:
        """Query cached vulnerabilities from the database."""
        if vendor == "unknown" or product == "unknown":
            logging.warning(f"Skipping cache query for unknown vendor or product: {vendor}:{product}")
            return []

        cpe_string = f"cpe:2.3:{part}:{vendor}:{product}:{version if version else '*'}:*:*:*:*:*:*:*"
        logging.info(f"Querying cached vulnerabilities for CPE: {cpe_string}")

        try:
            conn = self._connect_db()
            cursor = conn.cursor()
            query = """
                SELECT cve_id, cpe, description, published, last_modified,
                       cvss_score, cvss_vector, vuln_references, configurations
                FROM vulnerabilities
                WHERE cpe = ?
            """
            cursor.execute(query, (cpe_string,))
            rows = cursor.fetchall()
            vulnerabilities = []
            for row in rows:
                vuln = {
                    "cve_id": row[0],
                    "cpe": row[1],
                    "description": row[2],
                    "published": row[3],
                    "last_modified": row[4],
                    "cvss_score": row[5],
                    "cvss_vector": row[6],
                    "vuln_references": json.loads(row[7]) if row[7] else [],
                    "configurations": json.loads(row[8]) if row[8] else [],
                    "severity": self._get_severity_from_cvss(row[5]),
                    "cvss": row[5] if row[5] is not None else "N/A",
                    "recommendations": ["Update to the latest version", "Apply security patches"]
                }
                vulnerabilities.append(vuln)
            logging.info(f"Found {len(vulnerabilities)} cached vulnerabilities for {cpe_string}")
            return vulnerabilities
        except sqlite3.Error as e:
            logging.error(f"Database query error: {str(e)}")
            return []

    def _get_severity_from_cvss(self, cvss_score: Optional[float]) -> str:
        """Get severity level from CVSS score."""
        if cvss_score is None:
            return "Unknown"
        if cvss_score >= 9.0:
            return "Critical"
        elif cvss_score >= 7.0:
            return "High"
        elif cvss_score >= 4.0:
            return "Medium"
        elif cvss_score > 0.0:
            return "Low"
        else:
            return "None"

    def _fetch_nvd_vulnerabilities(self, part: str, vendor: str, product: str, version: Optional[str] = None) -> List[Dict]:
        """Fetch vulnerabilities from NVD API."""
        cpe_string = self._validate_cpe(part, vendor, product, version)
        if not cpe_string:
            logging.warning(f"Skipping NVD request for {vendor}:{product} due to invalid CPE")
            return []

        if product == "wordpress":
            logging.info("Skipping NVD request for WordPress due to unreliable vulnerability data")
            return []

        if not version and product in ["openssh"]:  # Skip versionless queries for broad products
            logging.warning(f"Skipping NVD query for {vendor}:{product} without specific version")
            return []

        vulnerabilities = []
        retries = 3
        for attempt in range(retries):
            try:
                cve_results = nvdlib.searchCVE(
                    cpeName=cpe_string,
                    limit=1000,
                    key=self.api_key if self.api_key else None,
                    delay=6 if not self.api_key else 0.6
                )
                for cve in cve_results:
                    description = next((desc.value for desc in cve.descriptions if desc.lang == "en"), "No description")
                    cvss_score = None
                    cvss_vector = None
                    severity = "Unknown"

                    # Extract CVSS score and vector
                    try:
                        if hasattr(cve, 'metrics'):
                            if hasattr(cve.metrics, 'cvssMetricV31') and cve.metrics.cvssMetricV31:
                                cvss_score = cve.metrics.cvssMetricV31[0].cvssData.baseScore
                                cvss_vector = cve.metrics.cvssMetricV31[0].cvssData.vectorString
                            elif hasattr(cve.metrics, 'cvssMetricV30') and cve.metrics.cvssMetricV30:
                                cvss_score = cve.metrics.cvssMetricV30[0].cvssData.baseScore
                                cvss_vector = cve.metrics.cvssMetricV30[0].cvssData.vectorString
                            elif hasattr(cve.metrics, 'cvssMetricV2') and cve.metrics.cvssMetricV2:
                                cvss_score = cve.metrics.cvssMetricV2[0].baseScore
                                cvss_vector = cve.metrics.cvssMetricV2[0].vectorString
                            else:
                                logging.warning(f"No CVSS metrics found for CVE {cve.id}")
                        else:
                            logging.warning(f"No metrics attribute for CVE {cve.id}")
                    except Exception as e:
                        logging.error(f"Error extracting CVSS for CVE {cve.id}: {str(e)}")
                        continue  # Skip this CVE if CVSS extraction fails

                    # Determine severity based on CVSS score
                    severity = self._get_severity_from_cvss(cvss_score)

                    references = [ref.url for ref in cve.references] if hasattr(cve, 'references') else []
                    configurations = []
                    if hasattr(cve, 'configurations'):
                        for config in cve.configurations:
                            if hasattr(config, 'nodes'):
                                config_data = {"nodes": []}
                                for node in config.nodes:
                                    if hasattr(node, 'cpeMatch'):
                                        node_data = {"cpeMatch": []}
                                        for match in node.cpeMatch:
                                            if hasattr(match, 'vulnerable') and hasattr(match, 'criteria'):
                                                match_data = {
                                                    "vulnerable": match.vulnerable,
                                                    "criteria": match.criteria
                                                }
                                                node_data["cpeMatch"].append(match_data)
                                        config_data["nodes"].append(node_data)
                                configurations.append(config_data)

                    vuln = {
                        "cve_id": cve.id,
                        "cpe": cpe_string,
                        "description": description,
                        "published": getattr(cve, 'published', ''),
                        "last_modified": getattr(cve, 'lastModified', ''),
                        "cvss_score": cvss_score,
                        "cvss_vector": cvss_vector,
                        "vuln_references": references,
                        "configurations": configurations,
                        "severity": severity,
                        "cvss": cvss_score if cvss_score is not None else "N/A",
                        "recommendations": ["Update to the latest version", "Apply security patches"]
                    }
                    vulnerabilities.append(vuln)

                if vulnerabilities:
                    try:
                        conn = self._connect_db()
                        cursor = conn.cursor()
                        for vuln in vulnerabilities:
                            logging.info(f"Caching vulnerability {vuln['cve_id']} for CPE {vuln['cpe']}")
                            cursor.execute("""
                                INSERT OR REPLACE INTO vulnerabilities (
                                    cve_id, cpe, description, published, last_modified,
                                    cvss_score, cvss_vector, vuln_references, configurations
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, (
                                vuln["cve_id"],
                                vuln["cpe"],
                                vuln["description"],
                                vuln["published"],
                                vuln["last_modified"],
                                vuln["cvss_score"],
                                vuln["cvss_vector"],
                                json.dumps(vuln["vuln_references"]),
                                json.dumps(vuln["configurations"])
                            ))
                        conn.commit()
                        logging.info(f"Cached {len(vulnerabilities)} vulnerabilities for {cpe_string}")
                    except sqlite3.Error as e:
                        logging.error(f"Failed to cache vulnerabilities: {str(e)}")
                        raise
                return vulnerabilities
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 404:
                    logging.warning(f"No vulnerabilities for CPE {cpe_string}")
                    return []
                if e.response.status_code in [429, 403]:
                    wait_time = 2 ** attempt
                    logging.warning(f"Rate limit exceeded, retrying in {wait_time} seconds...")
                    time.sleep(wait_time)
                    continue
                logging.error(f"NVD request error for {vendor}:{product}: {str(e)}")
                return []
            except Exception as e:
                logging.error(f"NVD request error for {vendor}:{product}: {str(e)}")
                return []
        logging.error(f"Failed to fetch data after {retries} attempts for {cpe_string}")
        return []

    def analyze_network(self, network_data: Dict) -> List[Dict]:
        """Analyze the network for vulnerabilities."""
        findings = []
        seen_cves = set()
        for host in network_data.get("hosts", []):
            if host.get("status") != "active":
                continue
            ip = host.get("ip", "unknown")
            ports = host.get("ports", [])
            services = host.get("services", [])

            for service in services:
                part, vendor, product, version = self._get_cpe_for_service(service)
                if vendor == "unknown" or product == "unknown":
                    continue

                vulnerabilities = self._query_cached_vulnerabilities(part, vendor, product, version)
                if not vulnerabilities:
                    logging.info(f"Cache empty, querying NVD for {vendor}:{product} (version: {version})")
                    vulnerabilities = self._fetch_nvd_vulnerabilities(part, vendor, product, version)

                for vuln in vulnerabilities:
                    cve_key = f"{vuln['cve_id']}:{service}"
                    if cve_key in seen_cves:
                        continue
                    seen_cves.add(cve_key)
                    findings.append({
                        "ip": ip,
                        "ports": ports,
                        "service": service,
                        "cve_id": vuln["cve_id"],
                        "description": vuln["description"],
                        "severity": vuln["severity"],
                        "cvss": vuln["cvss"],
                        "recommendations": vuln["recommendations"]
                    })

        logging.info(f"Found {len(findings)} vulnerabilities")
        return findings

    def generate_all_reports(self, network_data: Dict, language: str = "en") -> Dict:
        """Generate all report variants and create a ZIP archive."""
        findings = self.analyze_network(network_data)
        reports = []
        reports.append(self.report_generator.generate_no_gradient_black(network_data, findings, language))
        reports.append(self.report_generator.generate_no_gradient_black_booklet(network_data, findings, language))
        reports.append(self.report_generator.generate_gradient_white_black(network_data, findings, language))
        reports.append(self.report_generator.generate_gradient_white_black_booklet(network_data, findings, language))
        
        zip_filename = f"{network_data.get('location', 'Report').replace(' ', '_')}_{language}.zip"
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for report_file in reports:
                if os.path.exists(report_file):
                    zipf.write(report_file, os.path.basename(report_file))
                    logging.info(f"Added file to archive: {report_file}")
        
        logging.info(f"ZIP archive created: {zip_filename}")
        return {"reports": reports, "archive": zip_filename}

    def __del__(self):
        """Close the database connection when the object is destroyed."""
        if self._db_conn:
            self._db_conn.close()