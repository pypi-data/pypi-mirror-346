"""
Vulnerability analyzer for scanning networks and generating reports.
"""

import sqlite3
import json
import os
import zipfile
import re
from typing import Dict, List, Tuple, Optional, Any
import nvdlib
import time
import requests
from packaging import version

from .report_generator import ReportGenerator
from .config import config
from .nvd_client import NVDClient
from .database import NVDDatabase
from .logger import get_logger

logger = get_logger(__name__)


class VulnerabilityAnalyzer:
    """A class for analyzing security vulnerabilities.
    
    This class provides functionality to analyze security vulnerabilities
    using the National Vulnerability Database (NVD).
    
    Attributes:
        client (NVDClient): Client for interacting with NVD API
        db (NVDDatabase): Database for storing vulnerability data
    """

    def __init__(self, db_path: Optional[str] = None):
        """Initialize the VulnerabilityAnalyzer with NVD client and database."""
        self.base_path = os.path.dirname(os.path.abspath(__file__))
        self.db_path = db_path if db_path is not None else config.NVD_DB_PATH
        self.report_generator = ReportGenerator()
        self.api_key = config.NVD_API_KEY
        self.reports_dir = os.path.join(self.base_path, "output", "reports")
        self._db_conn = None
        if not self.api_key:
            logger.info("No NVD API key provided. Operating without API key.")
        else:
            logger.info(f"Using API key: {self.api_key[:8]}...")

        # CPE mapping for known services
        self.CPE_MAPPING = {
            "apache httpd": {"vendor": "apache", "part": "a", "product": "http_server"},
            "nginx": {"vendor": "nginx", "part": "a", "product": "nginx"},
            "mysql": {"vendor": "oracle", "part": "a", "product": "mysql"},
            "windows server": {"vendor": "microsoft", "part": "o", "product": "windows_server"},
            "wordpress": {"vendor": "wordpress", "part": "a", "product": "wordpress"},
            "tomcat": {"vendor": "apache", "part": "a", "product": "tomcat"},
            "openssl": {"vendor": "openssl", "part": "a", "product": "openssl"},
            "php": {"vendor": "php", "part": "a", "product": "php"},
            "java": {"vendor": "oracle", "part": "a", "product": "jdk"},
            "openssh": {"vendor": "openbsd", "part": "a", "product": "openssh"},
            "smb": {"vendor": "samba", "part": "a", "product": "samba"},
            "ubuntu": {"vendor": "canonical", "part": "o", "product": "ubuntu_linux"}
        }

        self.client = NVDClient()
        self.db = NVDDatabase()

        self._initialize_database()

    def _initialize_database(self):
        """Initialize the SQLite database."""
        try:
            logger.info(f"Attempting to initialize database at {self.db_path}")
            self._db_conn = sqlite3.connect(self.db_path)
            cursor = self._db_conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS vulnerabilities (
                    cve_id TEXT,
                    cpe TEXT,
                    description TEXT,
                    published TEXT,
                    last_modified TEXT,
                    cvss_score REAL,
                    cvss_vector TEXT,
                    vuln_references TEXT,
                    configurations TEXT,
                    PRIMARY KEY (cve_id, cpe)
                )
            """)
            
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_cpe ON vulnerabilities(cpe)")
            
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='vulnerabilities'")
            if not cursor.fetchone():
                logger.error("Failed to create vulnerabilities table")
                raise sqlite3.OperationalError("Failed to create vulnerabilities table")
                
            self._db_conn.commit()
            logger.info(f"Database initialized successfully at {self.db_path}")
        except sqlite3.Error as e:
            logger.error(f"Failed to initialize database: {str(e)}")
            raise

    def _connect_db(self) -> sqlite3.Connection:
        try:
            conn = sqlite3.connect(self.db_path)
            logger.info("Подключение к базе данных успешно")
            return conn
        except sqlite3.Error as e:
            logger.error(f"Ошибка подключения к базе данных: {str(e)}")
            raise

    def _query_cached_vulnerabilities(self, part: str, vendor: str, product: str, version: Optional[str] = None, ip_address: str = "unknown") -> List[Dict]:
        conn = self._connect_db()
        cursor = conn.cursor()
        try:
            query = """
                SELECT cve_id, cpe, description, severity, cvss, recommendations
                FROM vulnerabilities
                WHERE cpe LIKE ?
            """
            cpe_pattern = f"cpe:2.3:{part}:{vendor}:{product}:{version}%"
            cursor.execute(query, (cpe_pattern,))
            rows = cursor.fetchall()
            vulnerabilities = []
            for row in rows:
                cve_id = row[0]
                # Ищем эксплойты для каждой уязвимости
                vulnerabilities.append({
                    "cve_id": cve_id,
                    "cpe": row[1],
                    "description": row[2],
                    "severity": row[3],
                    "cvss": row[4],
                    "recommendations": json.loads(row[5]) if row[5] else [],
                })
            logger.info(f"Найдено кэшированных уязвимостей для {vendor}:{product} (версия: {version}): {len(vulnerabilities)}")
            return vulnerabilities
        except sqlite3.Error as e:
            logger.error(f"Ошибка запроса к базе данных: {str(e)}")
            return []
        finally:
            conn.close()

    def _fetch_nvd_vulnerabilities(self, part: str, vendor: str, product: str, version: Optional[str] = None, ip_address: str = "unknown") -> List[Dict]:
        cpe_string = self._validate_cpe(part, vendor, product, version)
        vulnerabilities = []
        tried_fallback = False
        fallback_mode = False
        if not cpe_string:
            logger.warning(f"Пропуск запроса к NVD для {vendor}:{product} из-за отсутствия валидного CPE")
            return []

        if product == "wordpress":
            logger.info(f"Пропуск запроса к NVD для WordPress, так как уязвимости не надежны в NVD")
            return []

        retries = 3
        for attempt in range(retries):
            try:
                cve_results = nvdlib.searchCVE(cpeName=cpe_string, limit=1000, key=self.api_key, delay=1.0)
                logger.debug(f"Ответ NVD для CPE {cpe_string}: {len(cve_results)} уязвимостей")
                for cve in cve_results:
                    logger.info(f"Обработка CVE: {cve.id}")
                    description = cve.descriptions[0].value if cve.descriptions else "Нет описания"
                    cvss = None
                    severity = "N/A"
                    is_affected = False

                    if hasattr(cve, 'metrics') and cve.metrics:
                        if hasattr(cve.metrics, 'cvssMetricV31') and cve.metrics.cvssMetricV31:
                            cvss = cve.metrics.cvssMetricV31[0].cvssData.baseScore
                            severity = self._get_severity_from_cvss(cvss)
                            logger.debug(f"CVE {cve.id}: CVSS v3.1 = {cvss}, Severity = {severity}")
                        elif hasattr(cve.metrics, 'cvssMetricV30') and cve.metrics.cvssMetricV30:
                            cvss = cve.metrics.cvssMetricV30[0].cvssData.baseScore
                            severity = self._get_severity_from_cvss(cvss)
                            logger.debug(f"CVE {cve.id}: CVSS v3.0 = {cvss}, Severity = {severity}")
                        elif hasattr(cve.metrics, 'cvssMetricV2') and cve.metrics.cvssMetricV2:
                            cvss = cve.metrics.cvssMetricV2[0].cvssData.baseScore
                            severity = self._get_severity_from_cvss(cvss)
                            logger.debug(f"CVE {cve.id}: CVSS v2.0 = {cvss}, Severity = {severity}")
                        else:
                            logger.warning(f"CVE {cve.id}: Метрики CVSS отсутствуют в metrics")
                    else:
                        logger.warning(f"CVE {cve.id}: Поле metrics отсутствует")

                    if version and not fallback_mode:
                        logger.debug(f"Проверка версии {version} для CVE {cve.id}")
                        if self._check_version_in_description(description, version):
                            is_affected = True
                            logger.debug(f"CVE {cve.id} затронута: найдена версия {version} в описании")
                        elif hasattr(cve, 'configurations'):
                            for config in cve.configurations:
                                if not hasattr(config, 'nodes'):
                                    continue
                                for node in config.nodes:
                                    if not hasattr(node, 'cpeMatch'):
                                        continue
                                    for cpe_match in node.cpeMatch:
                                        if not hasattr(cpe_match, 'criteria'):
                                            continue
                                        # Проверяем точное совпадение версии в criteria
                                        criteria = getattr(cpe_match, 'criteria', '')
                                        if criteria and version in criteria:
                                            is_affected = True
                                            logger.debug(f"CVE {cve.id} затронута: версия {version} найдена в criteria: {criteria}")
                                            break
                                        # Проверяем диапазоны версий
                                        affected_versions = None
                                        for attr in ['versionEndIncluding', 'versionEndExcluding', 'versionStartIncluding', 'versionStartExcluding']:
                                            if hasattr(cpe_match, attr):
                                                affected_versions = getattr(cpe_match, attr)
                                                logger.debug(f"Проверка {attr} для CVE {cve.id}: {affected_versions} против {version}")
                                                if affected_versions and self._is_version_affected(version, affected_versions):
                                                    is_affected = True
                                                    logger.debug(f"CVE {cve.id} затронута: {version} входит в диапазон {affected_versions}")
                                                    break
                                        if is_affected:
                                            break
                                    if is_affected:
                                        break
                                if is_affected:
                                    break
                        if not is_affected:
                            logger.debug(f"Пропуск CVE {cve.id} для {vendor}:{product}:{version} - версия не затронута")
                            continue

                    if fallback_mode and version:
                        has_version_conditions = False
                        affected = False
                        if hasattr(cve, 'configurations'):
                            for config in cve.configurations:
                                if not hasattr(config, 'nodes'):
                                    continue
                                for node in config.nodes:
                                    if not hasattr(node, 'cpeMatch'):
                                        continue
                                    for cpe_match in node.cpeMatch:
                                        if not hasattr(cpe_match, 'criteria'):
                                            continue
                                        # Проверяем точное совпадение версии в criteria
                                        criteria = getattr(cpe_match, 'criteria', '')
                                        if criteria and version in criteria:
                                            affected = True
                                            has_version_conditions = True
                                            logger.debug(f"[FALLBACK] CVE {cve.id} затронута: версия {version} найдена в criteria: {criteria}")
                                            break
                                        for attr in ['versionEndIncluding', 'versionEndExcluding', 'versionStartIncluding', 'versionStartExcluding']:
                                            if hasattr(cpe_match, attr):
                                                val = getattr(cpe_match, attr)
                                                if val:
                                                    has_version_conditions = True
                                                    if self._is_version_affected(version, val):
                                                        affected = True
                                                        logger.debug(f"[FALLBACK] CVE {cve.id} затронута: {version} входит в диапазон {val}")
                                                        break
                                        if has_version_conditions and affected:
                                            break
                                    if has_version_conditions and affected:
                                        break
                                if has_version_conditions and affected:
                                    break
                            if has_version_conditions and not affected:
                                logger.debug(f"[FALLBACK] Пропуск CVE {cve.id} для {vendor}:{product}:{version} - условия по версии не совпали")
                                continue
                            if not has_version_conditions:
                                logger.debug(f"[FALLBACK] Пропуск CVE {cve.id} для {vendor}:{product}:{version} - нет условий по версии")
                                continue

                    recommendations = ["Обновите до последней версии", "Примените патчи безопасности"]
                    vuln = {
                        "cve_id": cve.id,
                        "cpe": cpe_string,
                        "description": description,
                        "severity": severity,
                        "cvss": cvss if cvss is not None else "N/A",
                        "recommendations": recommendations,
                    }
                    vulnerabilities.append(vuln)

                if not vulnerabilities and version and not tried_fallback:
                    logger.info(f"Fallback: повторный запрос по CPE без версии для {vendor}:{product}")
                    cpe_string_fallback = self._validate_cpe(part, vendor, product, None)
                    tried_fallback = True
                    if cpe_string_fallback and cpe_string_fallback != cpe_string:
                        cpe_string = cpe_string_fallback
                        fallback_mode = True
                        continue

                if vulnerabilities:
                    conn = self._connect_db()
                    cursor = conn.cursor()
                    try:
                        for vuln in vulnerabilities:
                            cursor.execute("""
                                INSERT OR REPLACE INTO vulnerabilities (cve_id, cpe, description, severity, cvss, recommendations)
                                VALUES (?, ?, ?, ?, ?, ?)
                            """, (
                                vuln["cve_id"],
                                vuln["cpe"],
                                vuln["description"],
                                vuln["severity"],
                                vuln["cvss"],
                                json.dumps(vuln["recommendations"])
                            ))
                        conn.commit()
                        logger.info(f"Кэшировано уязвимостей для {vendor}:{product}: {len(vulnerabilities)}")
                    except sqlite3.Error as e:
                        logger.error(f"Ошибка кэширования уязвимостей: {str(e)}")
                    finally:
                        conn.close()
                return vulnerabilities
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 404:
                    logger.warning(f"Нет уязвимостей для CPE {cpe_string}")
                    return []
                if e.response.status_code in [429, 403]:
                    logger.warning(f"Превышен лимит, повтор через {2 ** attempt} секунд...")
                    time.sleep(2 ** attempt)
                    continue
                logger.error(f"Ошибка запроса к NVD для {vendor}:{product}: {str(e)}")
                return []
            except Exception as e:
                logger.error(f"Ошибка запроса к NVD для {vendor}:{product}: {str(e)}")
                return []
        logger.error(f"Не удалось получить данные после {retries} попыток для {vendor}:{product}")
        return []

    def _get_cpe_for_service(self, service: str) -> Tuple[str, str, str, Optional[str]]:
        """Извлечение vendor, product, version из сервиса"""
        service_lower = service.lower()
        version = None

        if "windows server" in service_lower:
            version_match = re.search(r'windows server\s+(\d{4}|\d+\.\d+\.\d+)', service_lower)
            if version_match:
                version = version_match.group(1)
            service_name = "windows server"
        else:
            version_match = re.search(r'(\d+\.\d+(?:p\d+)?(?:\.\d+)?[\w\-]*)', service_lower)
            if version_match:
                version = version_match.group(1)
                service_name = service_lower.replace(version, '').strip()
            else:
                service_name = service_lower

        for key, cpe_info in self.CPE_MAPPING.items():
            if key in service_name:
                return (
                    cpe_info["part"],
                    cpe_info["vendor"],
                    cpe_info["product"],
                    version
                )
        logger.warning(f"Не найдено CPE для сервиса: {service}")
        return "a", "unknown", "unknown", None

    def _validate_cpe(self, part: str, vendor: str, product: str, version: Optional[str] = None) -> Optional[str]:
        """Поиск CPE с учетом версии"""
        for key, cpe_info in self.CPE_MAPPING.items():
            if cpe_info["vendor"] == vendor and cpe_info["product"] == product:
                if "cpe23" in cpe_info:
                    if version:
                        parts = cpe_info["cpe23"].split(":")
                        if len(parts) > 5:
                            parts[5] = version
                        return ":".join(parts)
                    return cpe_info["cpe23"]

        normalized_version = version
        if product == "jdk" and version and version.startswith("1.8.0_"):
            normalized_version = f"8u{version.split('_')[1]}"
        if product == "ubuntu_linux" and version:
            normalized_version = version.split(".")[0] + "." + version.split(".")[1]
        if product == "windows_server" and version:
            normalized_version = version if version.isdigit() else version.replace(".", "")

        keywords = []
        if product == "http_server":
            keywords.append("apache http_server")
        elif product == "jdk":
            keywords.append(f"oracle jdk {normalized_version}" if normalized_version else "oracle jdk")
        elif product == "openssh":
            keywords.append(f"openbsd openssh {normalized_version}" if normalized_version else "openbsd openssh")
        elif product == "samba":
            keywords.append(f"samba {normalized_version}" if normalized_version else "samba")
        else:
            keywords.append(f"{vendor} {product} {normalized_version}" if normalized_version else f"{vendor} {product}")

        for keyword in keywords:
            if not keyword:
                continue
            try:
                logger.info(f"Поиск CPE с ключевым словом: {keyword}")
                cpe_results = nvdlib.searchCPE(keywordSearch=keyword, key=self.api_key, delay=1.0)
                for cpe in cpe_results:
                    cpe_name = cpe.cpeName.lower()
                    if vendor.lower() in cpe_name and product.lower().replace('_', '') in cpe_name.replace('_', '').replace('-', ''):
                        if product == "samba" and any(x in cpe_name for x in ["rsync", "node.js", "samba-client", "samba-tng"]):
                            continue
                        if product == "wordpress" and "plugin" in cpe_name:
                            continue
                        if product == "http_server" and "http_server" not in cpe_name:
                            continue
                        if "igor_sysoev" in cpe_name:
                            continue
                        version_parts = normalized_version.split('.') if normalized_version else []
                        short_version = '.'.join(version_parts[:2]) if len(version_parts) >= 2 else normalized_version
                        if normalized_version and (short_version.lower() in cpe_name or normalized_version.lower() in cpe_name):
                            logger.info(f"Найден подходящий CPE: {cpe.cpeName}")
                            return cpe.cpeName
                        elif not normalized_version:
                            logger.info(f"Найден подходящий CPE: {cpe.cpeName}")
                            return cpe.cpeName
                logger.warning(f"Нет результатов для ключевого слова: {keyword}")
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 404:
                    logger.warning(f"Ошибка 404 для ключевого слова: {keyword}")
                    continue
                logger.error(f"Ошибка поиска CPE для {keyword}: {str(e)}")
                continue
            except Exception as e:
                logger.error(f"Ошибка поиска CPE для {keyword}: {str(e)}")
                continue

        logger.warning(f"Не найдено CPE для {vendor}:{product} (версия: {version})")
        return None

    def _get_severity_from_cvss(self, cvss_score: float) -> str:
        """Определяет критичность на основе CVSS"""
        if cvss_score >= 9.0:
            return "Critical"
        elif cvss_score >= 7.0:
            return "High"
        elif cvss_score >= 4.0:
            return "Medium"
        elif cvss_score > 0:
            return "Low"
        return "N/A"

    def _normalize_version(self, version_str: str) -> str:
        """Нормализует версию для сравнения"""
        if not version_str:
            return ""
        
        if 'openssh' in version_str.lower():
            match = re.search(r'(\d+\.\d+(?:p\d+)?)', version_str)
            if match:
                return match.group(1)
        
        version_str = re.sub(r'[a-zA-Z].*$', '', version_str)
        parts = version_str.split('.')
        normalized_parts = []
        for part in parts:
            digits = re.sub(r'[^0-9]', '', part)
            if digits:
                normalized_parts.append(digits)
                
        return '.'.join(normalized_parts)

    def _is_version_affected(self, target_version: str, affected_versions: str) -> bool:
        """Проверяет, попадает ли версия в диапазон уязвимых версий"""
        if not target_version or not affected_versions:
            return False
            
        target_version = self._normalize_version(target_version)
        if not target_version:
            return False
            
        if 'p' in target_version.lower():
            base_version, patch = target_version.split('p')
            target_version = base_version
            
        if ':' in affected_versions:
            start_ver, end_ver = affected_versions.split(':')
            start_ver = self._normalize_version(start_ver.strip())
            end_ver = self._normalize_version(end_ver.strip())
            
            if start_ver and end_ver:
                return version.parse(start_ver) <= version.parse(target_version) <= version.parse(end_ver)
            elif start_ver:
                return version.parse(target_version) >= version.parse(start_ver)
            elif end_ver:
                return version.parse(target_version) <= version.parse(end_ver)
        else:
            affected_ver = self._normalize_version(affected_versions)
            if affected_ver:
                return version.parse(target_version) == version.parse(affected_ver)
            
        return False

    def _check_version_in_description(self, description: str, target_version: str) -> bool:
        """Проверяет, соответствует ли версия описанию уязвимости"""
        if not description or not target_version:
            return False
            
        target_version = self._normalize_version(target_version)
        if not target_version:
            return False
            
        version_patterns = [
            r'before\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'prior\s+to\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'earlier\s+than\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'up\s+to\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'through\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'until\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'(\d+\.\d+(?:p\d+)?(?:\.\d+)?)\s+and\s+earlier',
            r'(\d+\.\d+(?:p\d+)?(?:\.\d+)?)\s+or\s+earlier',
            r'version\s+(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'v(\d+\.\d+(?:p\d+)?(?:\.\d+)?)',
            r'(\d+\.\d+(?:p\d+)?(?:\.\d+)?)\s+version'
        ]
        
        for pattern in version_patterns:
            matches = re.finditer(pattern, description.lower())
            for match in matches:
                affected_ver = self._normalize_version(match.group(1))
                if affected_ver:
                    try:
                        if version.parse(target_version) <= version.parse(affected_ver):
                            return True
                    except version.InvalidVersion:
                        logger.warning(f"Невалидная версия для сравнения: {target_version} vs {affected_ver}")
                        continue
        return False

    def analyze_network(self, network_data: Dict) -> List[Dict]:
        findings = []
        seen_cves = set()
        for host in network_data.get("hosts", []):
            if host.get("status") != "active":
                continue
            ip = host.get("ip", "unknown")
            ports = host.get("ports", [])
            services = host.get("services", [])

            for service in services:
                part, vendor, product, version = self._get_cpe_for_service(service)
                if vendor == "unknown":
                    continue

                vulnerabilities = self._query_cached_vulnerabilities(part, vendor, product, version, ip)
                if not vulnerabilities:
                    logger.info(f"Кэш пуст, запрашиваем NVD для {vendor}:{product} (версия: {version}) на IP {ip}")
                    vulnerabilities = self._fetch_nvd_vulnerabilities(part, vendor, product, version, ip)

                for vuln in vulnerabilities:
                    cve_key = f"{vuln['cve_id']}:{service}"
                    if cve_key in seen_cves:
                        continue
                    seen_cves.add(cve_key)
                    findings.append({
                        "ip": ip,
                        "ports": ports,
                        "service": service,
                        "cve_id": vuln["cve_id"],
                        "description": vuln["description"],
                        "severity": vuln["severity"],
                        "cvss": vuln["cvss"],
                        "recommendations": vuln["recommendations"]
                    })

        logger.info(f"Обнаружено уязвимостей: {len(findings)}")
        return findings

    def generate_all_reports(self, network_data: Dict) -> Dict:
        findings = self.analyze_network(network_data)
        reports = []
        
        report_files = [
            self.report_generator.generate_no_gradient_black(network_data, findings),
            self.report_generator.generate_no_gradient_black_booklet(network_data, findings),
            self.report_generator.generate_gradient_white_black(network_data, findings),
            self.report_generator.generate_gradient_white_black_booklet(network_data, findings)
        ]
        
        # Создаем временную директорию для архива
        output_dir = os.path.join(self.base_path, "output")
        os.makedirs(output_dir, exist_ok=True)
        temp_dir = os.path.join(output_dir, "temp_archive")
        os.makedirs(temp_dir, exist_ok=True)
        
        # Перемещаем отчеты в reports/
        reports_dir = os.path.join(temp_dir, "reports")
        os.makedirs(reports_dir, exist_ok=True)
        
        for report_file in report_files:
            if os.path.exists(report_file):
                new_path = os.path.join(reports_dir, os.path.basename(report_file))
                os.rename(report_file, new_path)
                reports.append(new_path)
                logger.info(f"Отчет перемещен в: {new_path}")
        
        # Создаем архив с отчетами
        company_name = network_data.get('location', 'Report').replace(' ', '_')
        reports_zip = os.path.join(reports_dir, f"{company_name}.zip")
        with zipfile.ZipFile(reports_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for report_file in reports:
                if os.path.exists(report_file):
                    zipf.write(report_file, os.path.basename(report_file))
                    logger.info(f"Добавлен отчет в архив: {report_file}")
        
        # Создаем основной архив
        zip_filename = os.path.join(output_dir, "archive.zip")
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, temp_dir)
                    zipf.write(file_path, arcname)
                    logger.info(f"Добавлен файл в архив: {arcname}")
        
        # Удаляем временную директорию
        import shutil
        shutil.rmtree(temp_dir)
        
        logger.info(f"ZIP-архив создан: {zip_filename}")
        return {"reports": reports, "archive": zip_filename}

    def __del__(self):
        """Close the database connection when the object is destroyed."""
        if self._db_conn:
            self._db_conn.close()