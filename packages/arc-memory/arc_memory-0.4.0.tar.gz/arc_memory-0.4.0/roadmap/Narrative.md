# Arc: Strategic Narrative

![Arc Vision](../public/arc-vision.png)

## The Exponential AI Landscape

We are building Arc in an environment where AI code generation is advancing at an exponential rate. GitHub Copilot, Claude Code, and other AI coding tools are rapidly improving, with capabilities doubling every 6-12 months. This creates both urgency and opportunity for us as founders.

The pace of change is breathtaking. What took years now takes months. What took months now takes days. And in this acceleration, we've identified a critical gap that grows wider with each advancement in generative AI.

### Our Core Thesis

**As AI generates exponentially more code, the critical bottleneck shifts from generation to understanding.** Arc Memory's temporal knowledge graph becomes the essential 'world model' that enables both humans and AI to understand the 'why' behind code, creating a defensible moat through proprietary context that improves with every interaction. As frontier models like Gemini 2.5 Pro advance in function-calling capabilities, Arc becomes the essential memory layer that these models call for verified provenance and multi-agent coordination.

> **North Star:** Arc transforms every codebase into a continuously-evolving world model—a live, executable graph of architecture, rationale, and provenance that both humans and AI agents can query, update, and learn from.

![Arc Research Architecture](../public/arc-research-architecture.png)

#### Where We're Heading: Multi-Agent Coordination

Imagine upgrading OpenSSL across multiple services with two AI agents working in parallel:
- **Agent A** refactors low-level wrapper functions
- **Agent B** updates high-level API calls that depend on those wrappers

Without Arc Memory, Agent B might make changes assuming Agent A's work is complete, leading to integration errors and broken builds. But with Arc Memory:

1. Agent B queries the temporal knowledge graph to see the status of Agent A's wrapper changes
2. The Causal CRDT layer automatically buffers Agent B's API commit operation if its semantic dependency ("Wrapper tests pass") is not yet met
3. Both agents add provenance links to the knowledge graph (e.g., Agent B linking its API change to Agent A's specific commit using a `depends_on_commit` edge)
4. The result is a coordinated, error-free upgrade with a clear history of why each change was made

### Where we are today: Reviewing AI-Generated Code

While multi-agent coordination is our vision for the future, the immediate problem we're solving is much more pressing: reviewing multiple PRs written mostly by AI.

 > The "diff" is the new control loop for engineers. 

Today, senior engineers face the challenge of reviewing 5+ PRs daily, many generated by AI tools. They need to quickly understand:
- The logic behind AI's implementation decisions
- The business impact of these changes
- The potential technical debt being introduced

Arc Memory's hover cards provide this critical context directly in the PR review interface, showing:
- The requirements that drove the change
- Related architectural decisions
- Previous similar changes and their outcomes
- Potential impacts on other services

This transforms PR review from a time-consuming chore into a strategic activity focused on business logic validation and architectural guidance—precisely where human judgment adds the most value.

### Insights Shaping our Perspective

While most believe AI will replace human code review, we believe it will transform it into a higher-level activity focused on architectural decisions and business logic validation - precisely where contextual understanding becomes most critical.

The industry is fixated on improving code generation, but we see the emerging bottleneck in code understanding. As more code is generated faster, the ability to comprehend why decisions were made becomes the limiting factor in software development velocity and quality.

I've spent years watching engineering teams struggle with knowledge fragmentation. I've seen the pain of onboarding new developers to complex codebases. I've witnessed the frustration of tracking down the reasoning behind critical architectural decisions. And now, as AI accelerates code generation, these problems are becoming exponentially worse.

This narrative outlines our strategic plan to navigate this landscape, compressed into a 12-month timeline to match the accelerating pace of AI advancement.

## Our Three-Fold Challenge

Arc Memory is tackling three massive challenges simultaneously:

1. **The Context Problem**: As codebases grow and teams change, critical context is lost, leading to slower onboarding, repeated mistakes, and architectural drift
2. **The Provenance Problem**: As AI generates more code, tracking the origin, rationale, and verification of changes becomes essential for trust and accountability
3. **The Coordination Problem**: Multiple AI agents working on the same codebase need a shared understanding to collaborate effectively

### The Context Problem

Software development suffers from chronic amnesia. Critical context about why decisions were made is scattered across JIRA tickets, Slack threads, pull request comments, and team members' heads. When engineers leave, this context leaves with them. New team members spend months getting up to speed, and even experienced team members waste time rediscovering past decisions.

I've seen this firsthand. A senior engineer leaves, and suddenly no one knows why a critical architectural decision was made. The team spends weeks reverse-engineering the rationale, only to make the same mistakes that led to the original decision. This problem compounds as AI accelerates code generation. More code is written faster, with less human oversight of each line, making the preservation of context even more critical.

### The Provenance Problem

As AI generates more code, tracking the origin, rationale, and verification of changes becomes essential. Who or what generated this code? What requirements was it designed to meet? Has it been reviewed and verified by humans? Without answers to these questions, organizations face increasing risk and liability.

The industry is rushing toward AI-generated code without solving the fundamental problem of provenance. As regulations around AI accountability increase, this gap will become a critical liability for organizations that can't verify the origin and validation of their code.

### The Coordination Problem

The future of software development involves multiple specialized AI agents collaborating on the same codebase. These agents need a shared understanding to work together effectively. Without a common world model, they will work at cross-purposes, introducing conflicts and inconsistencies.

We're already seeing the early signs of this problem as teams integrate multiple AI tools into their workflow. Without a unified memory layer, these tools operate in silos, leading to fragmented understanding and conflicting recommendations.

## The Memory Layer for Engineering Teams

Arc is building the essential memory layer for the AI coding ecosystem. Our solution consists of three key components:

1. **Temporal Knowledge Graphs**: A continuously-updated graph connecting code changes to their context, requirements, and rationale
2. **Causal CRDTs**: A distributed data structure that enables collaborative editing while preserving causal relationships
3. **Provenance-Driven RL**: Reinforcement learning systems that improve based on the provenance and outcomes of past decisions


## What We Optimise For

**Arc exists to unlock flow for engineers, confidence for leaders, and context for AI.**
Every feature ladders up to five outcome pillars:

| Pillar           | Why it matters                                                                                        |
| ---------------- | ----------------------------------------------------------------------------------------------------- |
| **Velocity**     | Development feels “instant” again—PRs ship in minutes, not days.                                      |
| **Adoption**     | Arc becomes the tab teammates keep open; weekly usage is our north-star pulse.                        |
| **Trust**        | A suggestion is only useful if you can trace the *why*—we benchmark ourselves on provenance accuracy. |
| **Resilience**   | Incidents resolve faster because the graph points straight to root-cause and prior fixes.             |
| **Augmentation** | Agents get smarter when Arc feeds them context, measured as uplift in suggestion relevance and long time horizon tasks (ie. large scale refactoring).     |


---

## How We Reach Engineers (and Win Their Hearts)

**Bottom-up first, enterprise by demand.**

1. **Instant-on Extension** – One-click install, hover a diff, see the decision trail.
2. **Team Graph Spin-Up** – Share a link; Arc stitches your team’s context into the same timeline.
3. **Org Roll-Out** – SSO, custom integrations, audit controls—pulled in when leadership realises the graph is already their source of truth.

> **Primary users:** Staff & lead engineers drowning in AI-generated PRs.
> **Economic buyers:** Devs swipe a card → EMs buy seats → CTO mandates org-wide provenance.

---

## Roadmap at a Glance (12-Month Horizon)

| Wave                  | What ships                                                            | Signal we’re watching                                   |
| --------------------- | --------------------------------------------------------------------- | ------------------------------------------------------- |
| **Launch** (now-next) | GitHub extension + cloud graph API (function-call ready).             | “Aha!” under 2 min • First paying teams                 |
| **Expand**            | Incident views, natural-language graph search, early RL sandbox.      | Teams debugging with Arc open by default                |
| **Pioneer**           | AI suggestions with history, causal-CRDT prototype, multi-agent demo. | External agents hitting `arc.getDecisionTrail` at scale |

---

## How We Think about Compounding Value

1. **One Graph, Growing Context** 
   Every commit, ticket, and test run adds edges; the graph compounds instead of expiring.

2. **Tool-Agnostic Memory** 
   GitHub or GitLab, Linear or Jira—Arc sits above, not inside, any silo.

3. **Causal Merge Guarantees** 
   When parallel agents land patches, our CRDT layer reconciles intent, not just text.

4. **Open Function Schema** 
   Frontier models already speak JSON; Arc provides the plug-and-play provenance function so they don’t reinvent it

5. **Ecosystem Friendly** 
   Search engines, PR lint bots, incident dashboards—anything can query or write to Arc via GraphQL. We partner where others rebuild.

**End-state vision:** Arc is the neutral memory bus every AI-assisted IDE, CI system, and code agent opts into by default—because provenance is too hard (and too risky) to solve alone.


## Research Foundation

The ideas behind Arc build on current memory and coordination research.

| Theme                                       | Prior Work                                                           |
| ------------------------------------------- | -------------------------------------------------------------------- | 
| **Long-context & sequential collaboration** | Chain-of-Agents, Gemini 2 M-token windows                            | 
| **Graph-RAG & Hybrid-RAG**                  | Think-on-Graph 2.0, Hybrid-RAG papers                                | 
| **Memory stores for LLMs**                  | **Zep** (vector/metadata store), **Mem0** (conversation+tool memory) | 
| **Agent orchestration frameworks**          | LangGraph, LangChain                                                 | 
| **Causal consistency & Graph-CRDTs**        | Shapiro et al., recent graph-CRDT prototypes                         |
| **RL on software graphs**                   | SWE-RL, GitTemporalAI                                                | 
| **Provenance & supply-chain integrity**     | Software Heritage, SLSA                                              | 
| **Shared memory for multi-agent reasoning** | SRMT, Generative Agents                                              | 

**Net takeaway:** existing systems retrieve *better*, reason *deeper*, or merge *safer*—but never all three at once. Arc fuses Hybrid-RAG retrieval, causal CRDT synchronization, and provenance-driven RL into one live memory substrate built for AI-native engineering teams.

### Your Cue to Join Us

* **Graph engineers** who dream in edges and deltas.
* **Distributed-systems tinkerers** who want to crack causal CRDTs at scale.
* **Applied-AI researchers** eager to treat the codebase as an RL environment.

If building the memory layer for the next decade of software sounds like your arena, reach out: **[Jarrod@arc.computer](mailto:jarrod@arc.computer)**. Let’s give code a collective, provable memory—together.

