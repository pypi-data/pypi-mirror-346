Metadata-Version: 2.4
Name: capibara
Version: 2.1.7
Summary: CapibaraModel - Un modelo de lenguaje avanzado basado en arquitecturas modernas
Author-email: "Anachroni s.coop" <info@anachroni.co>
License: MIT
Project-URL: Documentation, https://capibara.readthedocs.io/en/latest/
Project-URL: Source, https://github.com/anachroni-io/capibara-model
Project-URL: Issues, https://github.com/anachroni-io/capibara-model/issues
Keywords: machine-learning,nlp,language-model,ssm,tpu,jax
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: jax>=0.4.23
Requires-Dist: jaxlib>=0.4.23
Requires-Dist: flax>=0.8.2
Requires-Dist: tensorflow>=2.16.1
Requires-Dist: transformers>=4.40.1
Requires-Dist: datasets>=2.18.1
Requires-Dist: accelerate>=0.29.2
Requires-Dist: wandb>=0.16.6
Requires-Dist: pydantic>=2.7.0
Requires-Dist: numpy>=1.26.4
Requires-Dist: pandas>=2.2.3
Requires-Dist: scipy>=1.15.2
Requires-Dist: optax>=0.1.9
Requires-Dist: chex>=0.1.9
Requires-Dist: orbax-checkpoint>=0.5.3
Requires-Dist: tensorboard>=2.19.0
Requires-Dist: safetensors>=0.4.2
Requires-Dist: tokenizers>=0.15.2
Requires-Dist: huggingface-hub>=0.20.3
Requires-Dist: protobuf>=4.25.3
Requires-Dist: PyYAML>=6.0.1
Requires-Dist: requests>=2.31.0
Requires-Dist: tqdm>=4.66.2
Requires-Dist: rich>=13.7.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: sentry-sdk>=2.8.0
Requires-Dist: psutil>=5.9.8
Requires-Dist: scikit-learn>=1.6.1
Requires-Dist: tensorflow-probability>=0.20.0
Requires-Dist: keras==3.9.0
Provides-Extra: dev
Requires-Dist: pytest<9.0.0,>=8.0.2; extra == "dev"
Requires-Dist: black<25.0.0,>=24.2.0; extra == "dev"
Requires-Dist: isort<6.0.0,>=5.13.2; extra == "dev"
Requires-Dist: mypy<2.0.0,>=1.8.0; extra == "dev"
Requires-Dist: flake8<8.0.0,>=7.0.0; extra == "dev"
Provides-Extra: tpu
Requires-Dist: libtpu<2.0.0,>=1.0.0; extra == "tpu"
Requires-Dist: cloud-tpu-client<1.0,>=0.10; extra == "tpu"
Provides-Extra: gpu
Requires-Dist: torch>=2.2.2; extra == "gpu"
Requires-Dist: torchaudio>=0.17.2; extra == "gpu"
Requires-Dist: torchvision>=0.17.2; extra == "gpu"
Requires-Dist: onnxruntime-gpu>=1.17.0; extra == "gpu"
Requires-Dist: bitsandbytes>=0.43.0; extra == "gpu"
Provides-Extra: cpu
Requires-Dist: torch>=2.2.2; extra == "cpu"
Requires-Dist: torchaudio>=0.17.2; extra == "cpu"
Requires-Dist: torchvision>=0.17.2; extra == "cpu"
Requires-Dist: onnxruntime>=1.17.0; extra == "cpu"

# CapibaraGPT-v2 ü¶´

Modelo de lenguaje avanzado con capacidades de interpretaci√≥n semi√≥tica y procesamiento de contexto din√°mico.

## üöÄ Caracter√≠sticas Principales

### 1. M√≥dulo Semi√≥tico
- **Interpretaci√≥n Multi-nivel**: An√°lisis literal, cultural y simb√≥lico
- **Atenci√≥n Cruzada**: Integraci√≥n din√°mica de contexto
- **Polisemia Adaptativa**: Pesos din√°micos por tipo de interpretaci√≥n
- **M√©tricas Sin Estado**: Compatible con JAX/Flax

### 2. Arquitectura Modular
- **Submodelos Especializados**: Cada m√≥dulo con responsabilidad √∫nica
- **Router Din√°mico**: Selecci√≥n inteligente de submodelos
- **Meta-loop**: Aprendizaje de patrones de uso

### 3. Procesamiento de Contexto
- **Atenci√≥n Multi-cabeza**: 4 cabezas de atenci√≥n
- **Conexiones Residuales**: Mejor flujo de gradientes
- **Dropout Adaptativo**: Regularizaci√≥n por tipo de interpretaci√≥n

## üõ†Ô∏è Instalaci√≥n

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/CapibaraGPT-v2.git
cd CapibaraGPT-v2

# Instalar dependencias
pip install -r requirements.txt
```

## üì¶ Dependencias Principales

```python
jax>=0.4.13
flax>=0.7.4
transformers>=4.30.0
numpy>=1.24.0
pandas>=2.0.0
```

## üß† Uso del M√≥dulo Semi√≥tico

```python
from capibara.sub_models.experimental.semio import SemioModule

# Inicializaci√≥n
semio = SemioModule(
    hidden_size=256,
    dropout_rate=0.1,
    num_heads=4
)

# Forward pass
output = semio(
    x=input_tensor,  # [batch, seq, hidden]
    context=context_tensor,  # [batch, ctx, hidden]
    training=True
)

# Acceso a resultados
interpretations = output["interpretations"]
weights = output["weights"]
semantic = output["semantic_projection"]
metrics = output["metrics"]
```

## üîç Caracter√≠sticas del M√≥dulo Semi√≥tico

### 1. Interpretaciones
- **Literal**: An√°lisis directo y denotativo
- **Cultural**: Interpretaci√≥n basada en contexto cultural
- **Simb√≥lica**: An√°lisis simb√≥lico y connotativo

### 2. Sistema de Pesos
- Proyecci√≥n sem√°ntica para enriquecimiento
- Pesos din√°micos por tipo de interpretaci√≥n
- Normalizaci√≥n mediante softmax

### 3. M√©tricas
- Score de polisemia
- Uso de contexto
- Pesos de interpretaci√≥n

## üéØ Ejemplos de Uso

### 1. An√°lisis Semi√≥tico B√°sico
```python
# An√°lisis de texto
result = semio.analyze_text("El gato negro cruz√≥ la calle")
print(result["interpretations"])
```

### 2. Integraci√≥n con Contexto
```python
# An√°lisis con contexto cultural
result = semio.analyze_with_context(
    text="El gato negro cruz√≥ la calle",
    context="En la cultura egipcia, los gatos negros..."
)
```

## üìä M√©tricas y Monitoreo

El m√≥dulo registra autom√°ticamente:
- Pesos de polisemia
- Salida de atenci√≥n
- Pesos de interpretaci√≥n
- Uso de contexto

## ü§ù Contribuci√≥n

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE.md](LICENSE.md) para m√°s detalles.

## üë• Autores

- **Anachroni s.coop** - *Desarrollo inicial* - [@gmarko](https://github.com/capibara-team)

## üôè Agradecimientos

- Inspirado en la teor√≠a semi√≥tica de Umberto Eco
- Basado en arquitecturas modernas de transformers
- Integraci√≥n con JAX/Flax para eficiencia computacional 
