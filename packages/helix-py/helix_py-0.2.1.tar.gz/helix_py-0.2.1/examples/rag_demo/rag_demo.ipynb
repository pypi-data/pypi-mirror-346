{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e3c2c3-cae0-4ee1-a25c-55fe498e8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q chonkie docling model2vec rich torch transformers tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbd7b3a-2032-4a18-8755-025983cd6426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/ln/dev/helix-py\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ln/Downloads/notebook_venv/lib/python3.12/site-packages (from helix-py==0.1.0) (2.2.5)\n",
      "Requirement already satisfied: pyarrow in /Users/ln/Downloads/notebook_venv/lib/python3.12/site-packages (from helix-py==0.1.0) (20.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/ln/Downloads/notebook_venv/lib/python3.12/site-packages (from helix-py==0.1.0) (4.67.1)\n",
      "Building wheels for collected packages: helix-py\n",
      "  Building wheel for helix-py (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for helix-py: filename=helix_py-0.1.0-py3-none-any.whl size=18683 sha256=20a3e00cd6c95113f14792c8319a5088d628dbe07fc73de5460bd0681f0bf41e\n",
      "  Stored in directory: /Users/ln/Library/Caches/pip/wheels/f9/37/7c/f0015793ba184eb4a2298b48b11a3bad96c63014471e2a40f2\n",
      "Successfully built helix-py\n",
      "Installing collected packages: helix-py\n",
      "Successfully installed helix-py-0.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install /Users/ln/dev/helix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7b0978-eb61-4447-8531-daac1da168b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chonkie import RecursiveChunker, RecursiveRules, RecursiveLevel\n",
    "from docling.document_converter import DocumentConverter\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "import helix\n",
    "from helix.client import Query\n",
    "from helix.types import Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7f8ea5-540b-496a-bad5-6a4882d4b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "# A wrapper to pretty print\n",
    "def rprint(text: str, console: Console=console, width: int = 80) -> None:\n",
    "  richtext = Text(text)\n",
    "  console.print(richtext.wrap(console, width=width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e93c5d0-e4af-4a8a-8e7d-2614876065b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589615a2-919a-4f03-9afe-3586415523b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "helix_docs_endpoints = [\n",
    "        \"https://docs.helix-db.com/info/hql\",\n",
    "        \"https://docs.helix-db.com/introduction/cookbook/basic\",\n",
    "        \"https://docs.helix-db.com/get-started/installation\",\n",
    "        \"https://docs.helix-db.com/get-started/sql-ingestion\"\n",
    "        \"https://docs.helix-db.com/hql/schema-definition\",\n",
    "        \"https://docs.helix-db.com/hql/query-structure\",\n",
    "        \"https://docs.helix-db.com/hql/source/source\",\n",
    "        \"https://docs.helix-db.com/hql/source/adding\",\n",
    "        \"https://docs.helix-db.com/hql/steps/traversals/steps_nodes\",\n",
    "        \"https://docs.helix-db.com/hql/steps/traversals/steps_edges\",\n",
    "        \"https://docs.helix-db.com/hql/steps/conditions\",\n",
    "        \"https://docs.helix-db.com/hql/steps/anonymous\",\n",
    "        \"https://docs.helix-db.com/hql/steps/properties/property-access\",\n",
    "        \"https://docs.helix-db.com/hql/steps/properties/property-additions\",\n",
    "        \"https://docs.helix-db.com/hql/steps/properties/property-exclusion\",\n",
    "        \"https://docs.helix-db.com/hql/steps/properties/property-remappings\",\n",
    "        \"https://docs.helix-db.com/hql/steps/deleting\",\n",
    "        \"https://docs.helix-db.com/hql/steps/updating\",\n",
    "        \"https://docs.helix-db.com/hql/steps/operations\",\n",
    "        \"https://docs.helix-db.com/hql/vectors/inserting\",\n",
    "        \"https://docs.helix-db.com/hql/vectors/searching\",\n",
    "        \"https://docs.helix-db.com/hql/types\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4861c58d-38e5-456b-8dc3-c904266c9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_menu_sections(text):\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = []\n",
    "    skip_count = 0\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # Check if we’re in a skip block\n",
    "        if skip_count > 0:\n",
    "            skip_count -= 1\n",
    "            i += 1\n",
    "            continue\n",
    "        # Check for the target headers\n",
    "        if line.startswith('##### Getting Started') or line.startswith('##### HelixQL'):\n",
    "            # Skip this line and the next 17 lines\n",
    "            skip_count = 17\n",
    "            i += 1\n",
    "            continue\n",
    "        # Keep the line if not skipping\n",
    "        cleaned_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    return '\\n'.join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a869854e-c324-475e-b53e-71b58081b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DocumentConverter()\n",
    "results = [converter.convert(doc) for doc in helix_docs_endpoints]\n",
    "text_results = [res.document.export_to_markdown() for res in results]\n",
    "text = \"\\n\".join(text_results)\n",
    "text = filter_menu_sections(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c4989d4-f62a-416f-a133-563c0dc28e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = RecursiveRules(\n",
    "    levels=[\n",
    "        RecursiveLevel(delimiters=['######', '#####', '####', '###', '##', '#']),\n",
    "        RecursiveLevel(delimiters=['\\n\\n', '\\n', '\\r\\n', '\\r']),\n",
    "        RecursiveLevel(delimiters='.?!;:'),\n",
    "        RecursiveLevel()\n",
    "    ]\n",
    ")\n",
    "chunker = RecursiveChunker(rules=rules, chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e235440a-70d3-47f0-80d4-c3ee7362f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "# What is a HQL?\n",
       "\n",
       "Helix Query Language (HQL) is a powerful graph traversal and similarity search \n",
       "query language\n",
       "\n",
       "## ​Documentation\n",
       "\n",
       "## Schema Definition\n",
       "\n",
       "Define and understand HQL schemas for your data\n",
       "\n",
       "## Query Structure\n",
       "\n",
       "Learn the basic structure and syntax of HQL queries\n",
       "\n",
       "## Graph Traversals\n",
       "\n",
       "Master graph traversal operations in HQL\n",
       "\n",
       "## Vector Operations\n",
       "\n",
       "Explore how to use vectors in HelixQL\n",
       "\n",
       "## Property Access\n",
       "\n",
       "Learn how to access and manipulate data properties\n",
       "\n",
       "## HelixQL Types\n",
       "\n",
       "Learn about the different types of data in HelixQL\n",
       "\n",
       "Was this page helpful?\n",
       "\n",
       "- Documentation\n",
       "\n",
       "# A basic example\n",
       "\n",
       "A basic example of how to use HelixDB\n",
       "\n",
       "We’re going to create a simple social network where users can follow each other \n",
       "and create posts.\n",
       "\n",
       "#\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "# What is a HQL?\n",
       "\n",
       "Helix Query Language (HQL) is a powerful graph traversal and similarity search \n",
       "query language\n",
       "\n",
       "## ​Documentation\n",
       "\n",
       "## Schema Definition\n",
       "\n",
       "Define and understand HQL schemas for your data\n",
       "\n",
       "## Query Structure\n",
       "\n",
       "Learn the basic structure and syntax of HQL queries\n",
       "\n",
       "## Graph Traversals\n",
       "\n",
       "Master graph traversal operations in HQL\n",
       "\n",
       "## Vector Operations\n",
       "\n",
       "Explore how to use vectors in HelixQL\n",
       "\n",
       "## Property Access\n",
       "\n",
       "Learn how to access and manipulate data properties\n",
       "\n",
       "## HelixQL Types\n",
       "\n",
       "Learn about the different types of data in HelixQL\n",
       "\n",
       "Was this page helpful?\n",
       "\n",
       "- Documentation\n",
       "\n",
       "# A basic example\n",
       "\n",
       "A basic example of how to use HelixDB\n",
       "\n",
       "We’re going to create a simple social network where users can follow each other \n",
       "and create posts.\n",
       "\n",
       "#\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## ​Step 1: Define the schema in schema.hx\n",
       "\n",
       "We’re going to define the schema for our social network in schema.hx.\n",
       "We’re going to have User nodes where users can Follow other users.\n",
       "We’re also going to have Post nodes where users can Create posts.\n",
       "\n",
       "```\n",
       "N::User {\n",
       "    name: String,\n",
       "    age: U32,\n",
       "    email: String,\n",
       "    created_at: I32,\n",
       "    updated_at: I32,\n",
       "}\n",
       "\n",
       "N::Post {\n",
       "    content: String,\n",
       "    created_at: I32,\n",
       "    updated_at: I32,\n",
       "}\n",
       "\n",
       "E::Follows {\n",
       "    From: User,\n",
       "    To: User,\n",
       "    Properties: {\n",
       "        since: I32,\n",
       "    }\n",
       "}\n",
       "\n",
       "E::Created {\n",
       "    From: User,\n",
       "    To: Post,\n",
       "    Properties: {\n",
       "        created_at: I32,\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "#\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## ​Step 1: Define the schema in schema.hx\n",
       "\n",
       "We’re going to define the schema for our social network in schema.hx.\n",
       "We’re going to have User nodes where users can Follow other users.\n",
       "We’re also going to have Post nodes where users can Create posts.\n",
       "\n",
       "```\n",
       "N::User {\n",
       "    name: String,\n",
       "    age: U32,\n",
       "    email: String,\n",
       "    created_at: I32,\n",
       "    updated_at: I32,\n",
       "}\n",
       "\n",
       "N::Post {\n",
       "    content: String,\n",
       "    created_at: I32,\n",
       "    updated_at: I32,\n",
       "}\n",
       "\n",
       "E::Follows {\n",
       "    From: User,\n",
       "    To: User,\n",
       "    Properties: {\n",
       "        since: I32,\n",
       "    }\n",
       "}\n",
       "\n",
       "E::Created {\n",
       "    From: User,\n",
       "    To: Post,\n",
       "    Properties: {\n",
       "        created_at: I32,\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "#\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## ​Step 2: Inserting data\n",
       "\n",
       "Creating a user is done by inserting a new node into the graph.\n",
       "\n",
       "```\n",
       "QUERY CreateUser(name: String, age: U32, email: String, now: I32) =&gt;\n",
       "    user &lt;- AddN&lt;User&gt;({name, age, email, created_at: now, updated_at: now})\n",
       "    RETURN user\n",
       "```\n",
       "\n",
       "To let users follow another user, we need to create an edge between them.\n",
       "\n",
       "```\n",
       "QUERY CreateFollow(follower_id: String, followed_id: String, now: I32) =&gt;\n",
       "    follower &lt;- N&lt;User&gt;(follower_id)\n",
       "    followed &lt;- N&lt;User&gt;(followed_id)\n",
       "    AddE&lt;Follows&gt;({since: now})::From(follower)::To(followed)\n",
       "    RETURN \"success\"\n",
       "```\n",
       "\n",
       "To create a post, we need to create a post node and an edge between the user and\n",
       "the post.\n",
       "\n",
       "```\n",
       "QUERY CreatePost(user_id: String, content: String, now: I32) =&gt;\n",
       "    user &lt;- N&lt;User&gt;(user_id)\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## ​Step 2: Inserting data\n",
       "\n",
       "Creating a user is done by inserting a new node into the graph.\n",
       "\n",
       "```\n",
       "QUERY CreateUser(name: String, age: U32, email: String, now: I32) =>\n",
       "    user <- AddN<User>({name, age, email, created_at: now, updated_at: now})\n",
       "    RETURN user\n",
       "```\n",
       "\n",
       "To let users follow another user, we need to create an edge between them.\n",
       "\n",
       "```\n",
       "QUERY CreateFollow(follower_id: String, followed_id: String, now: I32) =>\n",
       "    follower <- N<User>(follower_id)\n",
       "    followed <- N<User>(followed_id)\n",
       "    AddE<Follows>({since: now})::From(follower)::To(followed)\n",
       "    RETURN \"success\"\n",
       "```\n",
       "\n",
       "To create a post, we need to create a post node and an edge between the user and\n",
       "the post.\n",
       "\n",
       "```\n",
       "QUERY CreatePost(user_id: String, content: String, now: I32) =>\n",
       "    user <- N<User>(user_id)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    post &lt;- AddN&lt;Post&gt;({content, created_at: now, updated_at: now})\n",
       "    AddE&lt;Created&gt;({created_at: now})::From(user)::To(post)\n",
       "    RETURN post\n",
       "```\n",
       "\n",
       "#\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    post <- AddN<Post>({content, created_at: now, updated_at: now})\n",
       "    AddE<Created>({created_at: now})::From(user)::To(post)\n",
       "    RETURN post\n",
       "```\n",
       "\n",
       "#\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker(text)\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "# @title A quick look at our chunks~\n",
    "for chunk in chunks[:4]:\n",
    "    rprint(chunk.text)\n",
    "    print('-'*80, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79c59d3e-aa3f-407d-8246-6896f9cdc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().tolist()\n",
    "    return embedding\n",
    "\n",
    "def vectorize_chunked(chunked: List[str]) -> List[List[float]]:\n",
    "    # embedding dims: 768\n",
    "    vectorized = []\n",
    "    for chunk in tqdm(chunked):\n",
    "        embedding = vectorize_text(chunk)\n",
    "        vectorized.append(embedding)\n",
    "    return vectorized\n",
    "\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def get_ollama_response(prompt):\n",
    "    payload = {\n",
    "        #\"model\": \"deepseek-r1:7b\",\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"response\"]\n",
    "    else:\n",
    "        raise Exception(f\"Ollama API request failed with status {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea81ee1d-a316-47f8-ac80-8027931f7333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:02<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc length: 27538 chars, num of vectors: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items = [chunk.text for chunk in chunks]\n",
    "vectors = vectorize_chunked(items)\n",
    "print(f\"doc length: {len(text)} chars, num of vectors: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8e1f1173-b867-49cf-ac31-5dc91b6155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function to make LLM prompts with chunks\n",
    "def create_prompt(chunks: List[str], query: str) -> str:\n",
    "  prompt_template = \"\"\"<instructions>\n",
    "  Based on the provided contexts, answer the given question to the best of your ability. Remember to also add citations at appropriate points in the format of square brackets like [1][2][3], especially at sentence or paragraph endings.\n",
    "  You will be given a couple passages in the context, marked with a label 'Doc [1]:' to denote the passage number. Use that number for citations.\"\n",
    "  </instructions>\n",
    "\n",
    "  <context>\n",
    "  {context}\n",
    "  </context>\n",
    "\n",
    "  <query>\n",
    "  {query}\n",
    "  </query>\n",
    "  \"\"\"\n",
    "  context = \"\\n\\n\".join([f\"{chunk}\" for chunk in chunks])\n",
    "  prompt = prompt_template.format(context=context, query=query)\n",
    "  #print(prompt)\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5fac5349-271e-45fe-9e92-23773af0d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Helix instance found at 'http://0.0.0.0:6969'\n"
     ]
    }
   ],
   "source": [
    "db = helix.Client(local=True)\n",
    "\n",
    "class ragloaddocs(Query):\n",
    "    def __init__(self, docs: List[Tuple[str, List[Tuple[List[float], str]]]]):\n",
    "        super().__init__()\n",
    "        self.docs = docs\n",
    "\n",
    "    def query(self) -> List[Payload]: # TODO: batch send\n",
    "        docs_payload = []\n",
    "        for doc, vectors in self.docs:\n",
    "            docs_payload.append({ \"doc\": doc, \"vectors\": [{ \"vec\": vec, \"chunk\": chunk } for vec, chunk in vectors]})\n",
    "\n",
    "        return [{ \"docs\": docs_payload }]\n",
    "\n",
    "    def response(self, response):\n",
    "        return response\n",
    "\n",
    "class ragsearchdocs(Query):\n",
    "    def __init__(self, query_vector: List[float], k: int=4):\n",
    "        super().__init__()\n",
    "        self.query_vector = query_vector\n",
    "        self.k = k\n",
    "\n",
    "    def query(self) -> List[Payload]:\n",
    "        return [{ \"query\": self.query_vector, \"k\": self.k }]\n",
    "\n",
    "    def response(self, response):\n",
    "        return response.get(\"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76304885-135c-4dfc-b28c-025ab32f4f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Querying 'http://0.0.0.0:6969/ragloaddocs': 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.61it/s]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'message': 'Success'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert all the docs to vectors into helix\n",
    "db.query(ragloaddocs([(text, list(zip(vectors, items)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "04e1118d-a8c3-4981-ad95-102d87a1e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[HELIX]\u001b[0m Querying 'http://0.0.0.0:6969/ragsearchdocs': 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 139.01it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reponse: Based on the provided context, I can answer your question as follows:\n",
      "\n",
      "To explain traversals from nodes and get the nodes connected by outgoing edges of a specific type, you can use the `Out` and `OfType` operations in HelixQL.\n",
      "\n",
      "Here's an example query that demonstrates how to achieve this:\n",
      "\n",
      "```\n",
      "QUERY GetFollowers(followed_id: String) =>\n",
      "    followed <- N<User>(followed_id)\n",
      "    followers <- Out<Follows>()::From(followed)::To()\n",
      "    RETURN followers\n",
      "```\n",
      "\n",
      "In this query, we start from a node of type `User` with the ID `followed_id`. Then, we use the `Out` operation to traverse outwards from that node and get all edges of type `Follows`. The `::To()` part specifies that we want to follow these edges to their destinations. Finally, we return the list of followers.\n",
      "\n",
      "This query will give you all nodes connected by outgoing edges of type `Follows` from the specified `followed_id`.\n",
      "\n",
      "Please note that this is just an example based on the provided context, and you should adjust it according to your specific use case.\n",
      "\n",
      "References:\n",
      "\n",
      "[2] Doc[2]: This section provides a detailed explanation of how to create a user and follow another user, which includes using outgoing edges of type `Follows`.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Explain Traversals from Nodes. I want to get the nodes connected by outgoing edges of specific type.\"\n",
    "query_embedding = vectorize_text(user_prompt)\n",
    "res = db.query(ragsearchdocs(query_embedding, 6))[0]\n",
    "response = get_ollama_response(create_prompt([f\"Doc[{i+1}]: {text['content']}\" for i, text in enumerate(res)], user_prompt))\n",
    "print(f\"reponse: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00716de5-0fec-4df4-a8ba-cca09630d944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_venv",
   "language": "python",
   "name": "notebook_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
