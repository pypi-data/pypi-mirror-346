"""
This type stub file was generated by pyright.
"""

from pyarrow._fs import FileSystemHandler

"""
FileSystem abstraction to interact with various local and remote filesystems.
"""
FileStats = ...
_not_imported = ...
def __getattr__(name):
    ...

def copy_files(source, destination, source_filesystem=..., destination_filesystem=..., *, chunk_size=..., use_threads=...): # -> None:
    """
    Copy files between FileSystems.

    This functions allows you to recursively copy directories of files from
    one file system to another, such as from S3 to your local machine.

    Parameters
    ----------
    source : string
        Source file path or URI to a single file or directory.
        If a directory, files will be copied recursively from this path.
    destination : string
        Destination file path or URI. If `source` is a file, `destination`
        is also interpreted as the destination file (not directory).
        Directories will be created as necessary.
    source_filesystem : FileSystem, optional
        Source filesystem, needs to be specified if `source` is not a URI,
        otherwise inferred.
    destination_filesystem : FileSystem, optional
        Destination filesystem, needs to be specified if `destination` is not
        a URI, otherwise inferred.
    chunk_size : int, default 1MB
        The maximum size of block to read before flushing to the
        destination file. A larger chunk_size will use more memory while
        copying but may help accommodate high latency FileSystems.
    use_threads : bool, default True
        Whether to use multiple threads to accelerate copying.

    Examples
    --------
    Inspect an S3 bucket's files:

    >>> s3, path = fs.FileSystem.from_uri(
    ...            "s3://registry.opendata.aws/roda/ndjson/")
    >>> selector = fs.FileSelector(path)
    >>> s3.get_file_info(selector)
    [<FileInfo for 'registry.opendata.aws/roda/ndjson/index.ndjson':...]

    Copy one file from S3 bucket to a local directory:

    >>> fs.copy_files("s3://registry.opendata.aws/roda/ndjson/index.ndjson",
    ...               "file:///{}/index_copy.ndjson".format(local_path))

    >>> fs.LocalFileSystem().get_file_info(str(local_path)+
    ...                                    '/index_copy.ndjson')
    <FileInfo for '.../index_copy.ndjson': type=FileType.File, size=...>

    Copy file using a FileSystem object:

    >>> fs.copy_files("registry.opendata.aws/roda/ndjson/index.ndjson",
    ...               "file:///{}/index_copy.ndjson".format(local_path),
    ...               source_filesystem=fs.S3FileSystem())
    """
    ...

class FSSpecHandler(FileSystemHandler):
    """
    Handler for fsspec-based Python filesystems.

    https://filesystem-spec.readthedocs.io/en/latest/index.html

    Parameters
    ----------
    fs : FSSpec-compliant filesystem instance

    Examples
    --------
    >>> PyFileSystem(FSSpecHandler(fsspec_fs)) # doctest: +SKIP
    """
    def __init__(self, fs) -> None:
        ...
    
    def __eq__(self, other) -> bool:
        ...
    
    def __ne__(self, other) -> bool:
        ...
    
    def get_type_name(self): # -> str:
        ...
    
    def normalize_path(self, path):
        ...
    
    def get_file_info(self, paths): # -> list[Any]:
        ...
    
    def get_file_info_selector(self, selector): # -> list[Any]:
        ...
    
    def create_dir(self, path, recursive): # -> None:
        ...
    
    def delete_dir(self, path): # -> None:
        ...
    
    def delete_dir_contents(self, path, missing_dir_ok): # -> None:
        ...
    
    def delete_root_dir_contents(self): # -> None:
        ...
    
    def delete_file(self, path): # -> None:
        ...
    
    def move(self, src, dest): # -> None:
        ...
    
    def copy_file(self, src, dest): # -> None:
        ...
    
    def open_input_stream(self, path):
        ...
    
    def open_input_file(self, path):
        ...
    
    def open_output_stream(self, path, metadata):
        ...
    
    def open_append_stream(self, path, metadata):
        ...
    


