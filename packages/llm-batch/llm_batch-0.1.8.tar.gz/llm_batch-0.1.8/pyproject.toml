[project]
name = "llm-batch"
version = "0.1.8"
description = "Batch CLI tool for running batch inference with local LLMs"
readme = "README.md"
authors = [
    { name = "Marek Piotr Mysior" }
]
requires-python = ">=3.12"
dependencies = [
    "anthropic>=0.50.0",
    "click>=8.1.8",
    "instructor>=1.7.9",
    "openai>=1.76.0",
    "pillow>=11.2.1",
    "python-dotenv>=1.1.0",
    "pyyaml>=6.0.2",
]

[project.scripts]
llm-batch = "llmbatch.cli:cli"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    "pytest>=8.3.5",
    "tox>=4.25.0",
]

[tool.hatch.build.targets.wheel]
packages = ["src/llmbatch"]

[project.urls]
Homepage = "https://github.com/mmysior/llm-batch"
Issues = "https://github.com/mmysior/llm-batch/issues"