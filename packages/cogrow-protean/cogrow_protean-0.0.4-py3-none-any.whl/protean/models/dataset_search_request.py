# coding: utf-8

"""
    Protean API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 0.0.11
    Contact: support@cogrow.tech
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from protean.models.dataset_search_type import DatasetSearchType
from typing import Optional, Set
from typing_extensions import Self

class DatasetSearchRequest(BaseModel):
    """
    DatasetSearchRequest
    """ # noqa: E501
    query: Optional[StrictStr] = Field(default=None, description="The query to search for relevant data in the datasets.")
    limit: Optional[Annotated[int, Field(le=100, strict=True, ge=1)]] = Field(default=3, description="The maximum number of dataset chunks to return for the provided query.")
    dataset_ids: Optional[List[StrictStr]] = Field(default=None, description="The dataset IDs to run the query against. Expected values are either dataset GUID or *, where * will use all datasets that you are authorized for.", alias="datasetIds")
    score_threshold: Optional[Union[Annotated[float, Field(le=1, strict=True, ge=0)], Annotated[int, Field(le=1, strict=True, ge=0)]]] = Field(default=0.0, description="Cut off point for the relevance of dataset chunks to the provided user_message. Higher value implies higher level of relevance of the dataset chunks to the provided user_message.", alias="scoreThreshold")
    search_type: Optional[DatasetSearchType] = Field(default=None, description="Select the search type to use between full-text, similarity or hybrid which combines results full-text and similarity using Reciprocal Rank Fusion (RRF).", alias="searchType")
    use_reranker: Optional[StrictBool] = Field(default=True, description="Enable reranking the results of searches using advanced language models to improve relevance. After the initial retrieval (e.g., via full-text or vector search), results are re-scored based on semantic closeness to the query to get contextually accurate matches.", alias="useReranker")
    filter_expression: Optional[StrictStr] = Field(default=None, description="An optional filter expression used to narrow down the search results based on document metadata fields. Expressions can include logical operators like AND, OR, grouping with parentheses, and comparison operators such as ==, !=, >=, <=, IN, and NOT IN.", alias="filterExpression")
    __properties: ClassVar[List[str]] = ["query", "limit", "datasetIds", "scoreThreshold", "searchType", "useReranker", "filterExpression"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DatasetSearchRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DatasetSearchRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "query": obj.get("query"),
            "limit": obj.get("limit") if obj.get("limit") is not None else 3,
            "datasetIds": obj.get("datasetIds"),
            "scoreThreshold": obj.get("scoreThreshold") if obj.get("scoreThreshold") is not None else 0.0,
            "searchType": obj.get("searchType"),
            "useReranker": obj.get("useReranker") if obj.get("useReranker") is not None else True,
            "filterExpression": obj.get("filterExpression")
        })
        return _obj


