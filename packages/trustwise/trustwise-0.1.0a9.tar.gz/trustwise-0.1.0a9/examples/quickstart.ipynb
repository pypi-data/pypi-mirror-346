{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¦‰ Trustwise SDK Demo\n",
    "\n",
    "This notebook provides a comprehensive demonstration of the Trustwise SDK's capabilities for evaluating AI-generated content. We'll cover everything from basic setup to advanced features and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Environment Setup\n",
    "\n",
    "First, let's set up our environment and install the necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the latest version of Trustwise SDK\n",
    "# !pip install trustwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from trustwise.sdk import TrustwiseSDK\n",
    "from trustwise.sdk.config import TrustwiseConfig\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is set\n",
    "api_key = os.environ.get(\"TW_API_KEY\")\n",
    "assert api_key is not None, \"TW_API_KEY is not set in environment variables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SDK Configuration and Initialization\n",
    "\n",
    "The Trustwise SDK offers flexible configuration options. Let's explore different ways to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using environment variable (recommended)\n",
    "config = TrustwiseConfig()  # Automatically uses TW_API_KEY from environment\n",
    "trustwise = TrustwiseSDK(config)\n",
    "\n",
    "# Method 2: Direct initialization with API key\n",
    "config_direct = TrustwiseConfig(api_key=os.environ[\"TW_API_KEY\"])\n",
    "trustwise_direct = TrustwiseSDK(config_direct)\n",
    "\n",
    "# Method 3: Custom configuration with specific base URL\n",
    "config_custom = TrustwiseConfig(\n",
    "    api_key=os.environ[\"TW_API_KEY\"],\n",
    "    base_url=\"https://api.trustwise.ai\"\n",
    ")\n",
    "trustwise_custom = TrustwiseSDK(config_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding API Versioning\n",
    "\n",
    "The SDK uses a path-based versioning system that makes it easy to work with different API versions. Let's explore this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example context for our evaluations\n",
    "context = [{\n",
    "    \"node_text\": \"Paris is the capital of France. It is known for the Eiffel Tower and the Louvre Museum.\",\n",
    "    \"node_score\": 0.95,\n",
    "    \"node_id\": \"doc:idx:1\"\n",
    "}]\n",
    "\n",
    "# Using explicit version path (v3) - Recommended\n",
    "result_v3 = trustwise.safety.v3.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=context\n",
    ")\n",
    "print(\"V3 Result:\", result_v3)\n",
    "\n",
    "# Using default version (backward compatibility)\n",
    "result_default = trustwise.safety.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=context\n",
    ")\n",
    "print(\"Default Version Result:\", result_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Safety Metrics\n",
    "\n",
    "Let's explore the comprehensive safety metrics available in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Faithfulness Evaluation\n",
    "faithfulness = trustwise.safety.v3.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=context\n",
    ")\n",
    "print(\"Faithfulness Score:\", faithfulness.score)\n",
    "print(\"Facts:\", faithfulness.facts)\n",
    "\n",
    "# 4.2 PII Detection\n",
    "pii_text = \"My email is john@example.com and my phone is 123-456-7890\"\n",
    "pii_result = trustwise.safety.v3.pii.evaluate(\n",
    "    text=pii_text,\n",
    "    allowlist=[\"john@example.com\"],  # Allowed PII patterns\n",
    "    blocklist=[\"123-456-7890\"]      # Blocked PII patterns\n",
    ")\n",
    "print(\"\\nPII Detection Results:\")\n",
    "print(\"Identified PII:\", pii_result.identified_pii)\n",
    "\n",
    "# 4.3 Answer Relevancy\n",
    "relevancy = trustwise.safety.v3.answer_relevancy.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=context\n",
    ")\n",
    "print(\"\\nAnswer Relevancy Score:\", relevancy.score)\n",
    "print(\"Generated Question:\", relevancy.generated_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alignment Metrics\n",
    "\n",
    "Now let's look at the alignment metrics that help evaluate the quality and appropriateness of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Clarity Evaluation\n",
    "clarity = trustwise.alignment.v1.clarity.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\"\n",
    ")\n",
    "print(\"Clarity Score:\", clarity.score)\n",
    "\n",
    "# 5.2 Tone Analysis\n",
    "tone = trustwise.alignment.v1.tone.evaluate(\n",
    "    response=\"The capital of France is Paris.\"\n",
    ")\n",
    "print(\"\\nTone Analysis:\")\n",
    "for label, score in zip(tone.labels, tone.scores):\n",
    "    print(f\"{label}: {score:.2f}%\")\n",
    "\n",
    "# 5.3 Formality Check\n",
    "formality = trustwise.alignment.v1.formality.evaluate(\n",
    "    response=\"The capital of France is Paris.\"\n",
    ")\n",
    "print(\"\\nFormality Score:\", formality.score)\n",
    "print(\"Sentence Scores:\", dict(zip(formality.sentences, formality.scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics\n",
    "\n",
    "Let's explore the performance metrics for monitoring costs and environmental impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Cost Evaluation\n",
    "cost_result = trustwise.performance.v1.cost.evaluate(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    model_type=\"LLM\",\n",
    "    model_provider=\"OpenAI\",\n",
    "    number_of_queries=5,\n",
    "    total_prompt_tokens=950,\n",
    "    total_completion_tokens=50\n",
    ")\n",
    "print(\"Cost Analysis:\")\n",
    "print(f\"Cost per run: ${cost_result.cost_estimate_per_run:.4f}\")\n",
    "print(f\"Total project cost: ${cost_result.total_project_cost_estimate:.4f}\")\n",
    "\n",
    "# 6.2 Carbon Emissions\n",
    "carbon_result = trustwise.performance.v1.carbon.evaluate(\n",
    "    processor_name=\"AMD A10-9700\",\n",
    "    provider_name=\"aws\",\n",
    "    provider_region=\"us-east-1\",\n",
    "    instance_type=\"p4d.24xlarge\",\n",
    "    average_latency=100\n",
    ")\n",
    "print(\"\\nCarbon Emissions:\")\n",
    "print(f\"Carbon emissions: {carbon_result.carbon_emitted:.4f} kg CO2e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Types, JSON and auto-complete support\n",
    "\n",
    "Trustwise SDK supports both Response types and JSON for developer's ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Carbon Result:\", type(carbon_result), carbon_result)\n",
    "print(\"Carbon Emitted:\", carbon_result.carbon_emitted)\n",
    "print(\"Carbon Result JSON:\", carbon_result.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Guardrails (Experimental) and Validation\n",
    "\n",
    "Let's implement guardrails to automatically validate responses against multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-metric guardrail\n",
    "guardrail = trustwise.guardrails(\n",
    "    thresholds={\n",
    "        \"faithfulness\": 80,\n",
    "        \"answer_relevancy\": 70,\n",
    "        \"clarity\": 70\n",
    "    },\n",
    "    block_on_failure=True\n",
    ")\n",
    "\n",
    "# Test the guardrail with a good response\n",
    "good_response = \"The capital of France is Paris.\"\n",
    "good_evaluation = guardrail.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=good_response,\n",
    "    context=context\n",
    ")\n",
    "print(\"Good Response Evaluation:\")\n",
    "print(good_evaluation.to_json())\n",
    "\n",
    "# Test the guardrail with a poor response\n",
    "poor_response = \"I don't know the answer to that question.\"\n",
    "poor_evaluation = guardrail.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=poor_response,\n",
    "    context=context\n",
    ")\n",
    "print(\"\\nPoor Response Evaluation:\")\n",
    "print(poor_evaluation.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Handling and Best Practices\n",
    "\n",
    "Let's explore different types of errors you might encounter when using the SDK and how to handle them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 SDK Validation Errors\n",
    "\n",
    "The SDK uses Pydantic for input validation. Let's see how it handles invalid inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to evaluate with invalid input (missing required field)\n",
    "result = trustwise.safety.v3.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    # Missing 'response' parameter\n",
    "    context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to evaluate with invalid input type\n",
    "result = trustwise.safety.v3.faithfulness.evaluate(\n",
    "    query=123,  # Invalid type: should be string\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Backend API Errors\n",
    "\n",
    "When the backend API returns a non-200 response, the SDK will raise a `TrustwiseError` with the backend's error message. Let's see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from trustwise.sdk import TrustwiseSDK\n",
    "from trustwise.sdk.config import TrustwiseConfig\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "config = TrustwiseConfig()  # Automatically uses TW_API_KEY from environment\n",
    "trustwise = TrustwiseSDK(config)\n",
    "\n",
    "# Try to evaluate with invalid API key\n",
    "invalid_config = TrustwiseConfig(api_key=\"invalid_key\")\n",
    "invalid_sdk = TrustwiseSDK(invalid_config)\n",
    "result = invalid_sdk.safety.v3.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to evaluate with invalid context format\n",
    "invalid_context = [{\n",
    "    \"invalid_field\": \"This is not a valid context format\"\n",
    "}]\n",
    "result = trustwise.safety.v3.faithfulness.evaluate(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    "    context=invalid_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Comprehensive Error Handling\n",
    "\n",
    "Here's a practical example of how to handle both SDK validation errors and backend API errors in a production environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "from trustwise.sdk.exceptions import TrustwiseValidationError\n",
    "\n",
    "def safe_evaluate_with_error_handling(\n",
    "    query: str,\n",
    "    response: str,\n",
    "    context: list,\n",
    "    metric: str = \"faithfulness\"\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Safely evaluate a response with comprehensive error handling.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's query\n",
    "        response: The AI's response\n",
    "        context: The context used for evaluation\n",
    "        metric: The metric to evaluate (default: faithfulness)\n",
    "        \n",
    "    Returns:\n",
    "        Optional[Dict[str, Any]]: Evaluation results or error details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the appropriate evaluator based on the metric\n",
    "        evaluator = getattr(trustwise.safety.v3, metric)\n",
    "        \n",
    "        # Perform the evaluation\n",
    "        result = evaluator.evaluate(\n",
    "            query=query,\n",
    "            response=response,\n",
    "            context=context\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"score\": result.score,\n",
    "            \"details\": result.to_json()\n",
    "        }\n",
    "        \n",
    "    except TrustwiseValidationError as e:\n",
    "        print(f\"Trustwise Validation Error: {str(e)}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error_type\": \"trustwise_validation_error\",\n",
    "            \"error_message\": str(e)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {str(e)}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error_type\": \"unexpected_error\",\n",
    "            \"error_message\": str(e)\n",
    "        }\n",
    "\n",
    "# Test the error handling with various scenarios\n",
    "test_cases = [\n",
    "    # Valid case\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"response\": \"The capital of France is Paris.\",\n",
    "        \"context\": context,\n",
    "        \"description\": \"Valid input\"\n",
    "    },\n",
    "    # Invalid query type\n",
    "    {\n",
    "        \"query\": 123,  # Invalid type\n",
    "        \"response\": \"The capital of France is Paris.\",\n",
    "        \"context\": context,\n",
    "        \"description\": \"Invalid query type\"\n",
    "    },\n",
    "    # Invalid context format\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"response\": \"The capital of France is Paris.\",\n",
    "        \"context\": [{\"invalid\": \"format\"}],\n",
    "        \"description\": \"Invalid context format\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(f\"\\nTesting: {case['description']}\")\n",
    "    result = safe_evaluate_with_error_handling(\n",
    "        query=case[\"query\"],\n",
    "        response=case[\"response\"],\n",
    "        context=case[\"context\"]\n",
    "    )\n",
    "    print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Features\n",
    "\n",
    "This notebook has demonstrated the key features and capabilities of the Trustwise SDK:\n",
    "\n",
    "1. Flexible configuration and initialization\n",
    "2. Path-based API versioning\n",
    "3. Full test coverage for SDK + Installation\n",
    "4. Automated documentation support\n",
    "5. Guardrails (Experimental) and validation\n",
    "6. Structured Error handling\n",
    "7. Extensibility of .explain() / .batch_evaluate() features for future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
