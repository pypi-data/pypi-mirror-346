Metadata-Version: 2.4
Name: knowledge-base-builder
Version: 0.1.1
Summary: Build knowledge bases from multiple sources using large language models
Home-page: https://github.com/kostadindev/knowledge-base-builder
Author: Kostadin Devedzhiev
Author-email: kostadin.devedzhiev@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-google-genai>=0.0.5
Requires-Dist: langchain-community>=0.0.13
Requires-Dist: beautifulsoup4>=4.12.2
Requires-Dist: requests>=2.31.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: lxml>=4.9.3
Requires-Dist: pypdf>=3.17.0
Requires-Dist: python-docx>=0.8.11
Requires-Dist: markdown>=3.4.3
Requires-Dist: mistune>=2.0.5
Requires-Dist: striprtf>=0.0.22
Requires-Dist: pandas>=2.0.0
Requires-Dist: openpyxl>=3.1.2
Requires-Dist: ezodf>=0.3.2
Requires-Dist: pyyaml>=6.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ðŸ§  Multi-Source Knowledge Base Builder for LLMs

This project builds a web crawlable **textual knowledge base** from various data sources such as PDFs, websites, and GitHub markdown files, using **large language models** to structure and summarize the content. The final output is a **Markdown-formatted knowledge base**, ready for use as an llms.txt or llms-full.txt format. It can also be used in **RAG pipelines** and chatbots. Supports **Google Gemini**, **OpenAI GPT-4o**, and **Anthropic Claude**. The algorithm uses a logarithmic-depth parallel merge tree with a concurrency-limited semaphore to efficiently process and merge all documents.

---

## âœ¨ Features

- ðŸ“„ **Document ingestion** â€“ Downloads local or remote documents and extracts structured text.
- ðŸŒ **Website ingestion** â€“ Crawls pages from a sitemap or list of pages and extracts clean HTML content.
- ðŸ“˜ **GitHub integration**  â€“ Fetches Markdown files from public repositories.
- ðŸ§  **LLM-powered summarization** â€“ Uses state-of-the-art models to convert raw data into readable, structured Markdown.
- ðŸ” **Recursive merging** â€“ Combines multiple knowledge base sections into a single cohesive document.
- ðŸ”„ **Multiple model providers** â€“ Choose between Google Gemini, OpenAI GPT-4o, or Anthropic Claude 3.7 Sonnet.
- âš¡ **Performance** â€“ Load files in parallel and make multiple asynchronous calls to LLMs to summarize documents.

---

## ðŸš€ Installation

### Install from PyPI

```bash
pip install knowledge-base-builder
```

### Install from Source

```bash
git clone https://github.com/kostadindev/knowledge-base-builder.git
cd knowledge-base-builder
pip install -e .
```

---

## ðŸš€ Quickstart

### 1. Set up your `.env` file

Create a `.env` file in your project directory with the following variables (add the API keys for the models you intend to use):

```env

# You need only one of the following
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional if you want to include Github repositories with a high rate limit
GITHUB_API_KEY=your_github_api_key_here 
```

### 2. Use as a Python Package

```python
import os
from dotenv import load_dotenv
from knowledge_base_builder import KBBuilder

# Load environment variables
load_dotenv()

# API and model configuration
config = {
    'LLM_PROVIDER': 'gemini',  # Choose: 'gemini', 'openai', or 'anthropic'
    'GOOGLE_API_KEY': os.getenv("GOOGLE_API_KEY"),     # For Gemini
    'OPENAI_API_KEY': os.getenv("OPENAI_API_KEY"),     # For GPT-4o
    'ANTHROPIC_API_KEY': os.getenv("ANTHROPIC_API_KEY"), # For Claude
}

# Source documents - unified approach
    sources = {
        # Unified files list - automatically detects and processes each file type
        'files': [
            # PDF documents - remote
            "https://kostadindev.github.io/static/documents/cv.pdf",
            "https://kostadindev.github.io/static/documents/sbu_transcript.pdf",
            # Local file path (no need for file:/// prefix)
            "C:/Users/kosta/OneDrive/Desktop/MS Application Materials/emf-ellipse-publication.pdf",
            
            # Web pages
            "https://kostadindev.github.io/index.html",
            "https://kostadindev.github.io/projects.html",
            
            # Add other file types as needed
            # "https://example.com/data.csv",
            # "path/to/local/document.docx",  # Relative local path example
            # "https://example.com/api-docs.json",
        ],
        
        # Process all pages from a sitemap
        'sitemap_url': "https://kostadindev.github.io/sitemap.xml",
        
        # GitHub repositories to process (format: username/repo or full URL)
        'github_repositories': [
            "https://github.com/kostadindev/Knowledge-Base-Builder",
            "https://github.com/kostadindev/GONEXT",
            "https://github.com/kostadindev/GONEXT-ML",
            "https://github.com/kostadindev/meta-me",
            "https://github.com/kostadindev/Recursive-QA",
            "https://github.com/kostadindev/deep-gestures",
            "https://github.com/kostadindev/emf-ellipse"
        ]
    }
# Create KB builder
kbb = KBBuilder(config)

# Build knowledge base
kbb.build(sources=sources, output_file="final_knowledge_base.md")
```

---

## ðŸ”§ Supported Sources

| Source Type | Description | Formats |
|-------------|-------------|---------|
| Documents | Text documents | PDF, DOCX, TXT, MD, RTF |
| Spreadsheets | Tabular data | CSV, TSV, XLSX, ODS |
| Web Content | Structured web data | HTML, XML, JSON, YAML/YML |
| Websites | Live web pages | Any URL or sitemap |
| GitHub | Repository content | Markdown files from public repos |

> All sources can now be added through the unified `files` parameter, with automatic format detection.

---

## ðŸ§  LLM Providers

| Provider | Models | Features |
|----------|--------|----------|
| Google Gemini | gemini-2.0-flash (default) | Fast, cost-effective summaries |
| OpenAI | gpt-4o (default) | High-quality summaries, strong reasoning |
| Anthropic | claude-3-7-sonnet (default) | High-quality summaries, excellent formatting |

---

## ðŸ“¥ Output Example

```markdown
# Resume Summary

## Education
- B.S. in Computer Science from XYZ University

## Experience
- Software Engineer at ABC Corp
- Developed NLP-based document parsers...

---

# Website Summary

## Project Pages
- **Project Alpha**: A machine learning system for ...
- **Blog Post**: How to use Gemini with LangChain ...
```

---

## ðŸ§ª Upcoming Enhancements
- [ ] Add support for other data sources (Google Drive, LinkedIn)
- [ ] Support conversion from knowledge base to vector DB (e.g., Pinecone, Chroma)
- [ ] Implement additional async processing for better performance
- [ ] Improve performance of the logarithmic-depth parallel merge tree with a concurrency-limited semaphore

---

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

MIT Â© [Kostadin Devedzhiev](https://github.com/kostadindev)
